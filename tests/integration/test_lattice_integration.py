#!/usr/bin/env python3
"""
IRONFORGE Lattice Integration Test
==================================

Tests the fixed TimeframeLatticeMapper with Enhanced Session Adapter events
to verify all 2,888 events can be successfully mapped without KeyErrors.

This integration test validates:
- Enhanced Session Adapter ‚Üí Lattice Mapper data flow
- Defensive coding handles dictionary events
- All events are successfully mapped to coordinates
- Hot zones and connections are properly detected
- No KeyError exceptions occur

Author: IRONFORGE Archaeological Discovery System
Date: August 15, 2025
"""

import json
import sys
import time
from datetime import datetime
from pathlib import Path

# Add current directory to path for imports
sys.path.append(str(Path(__file__).parent))

from ironforge.analysis.enhanced_session_adapter import EnhancedSessionAdapter
from ironforge.analysis.timeframe_lattice_mapper import TimeframeLatticeMapper


class LatticeIntegrationTest:
    """Integration test for Enhanced Session Adapter ‚Üí Lattice Mapper pipeline"""
    
    def __init__(self):
        """Initialize test environment"""
        self.adapter = EnhancedSessionAdapter()
        self.mapper = TimeframeLatticeMapper(
            grid_resolution=100,
            min_node_events=1,  # Lower threshold for testing
            hot_zone_threshold=0.5  # Lower threshold for testing
        )
        self.test_results = {
            'timestamp': datetime.now().isoformat(),
            'tests_passed': 0,
            'tests_failed': 0,
            'total_events_processed': 0,
            'keyerror_count': 0,
            'nodes_created': 0,
            'connections_created': 0,
            'hot_zones_detected': 0,
            'performance_metrics': {}
        }
        
        print("üß™ IRONFORGE LATTICE INTEGRATION TEST")
        print("=" * 60)
        print(f"Test initialization timestamp: {self.test_results['timestamp']}")
    
    def run_comprehensive_test(self):
        """Run comprehensive integration test"""
        
        # Test 1: Enhanced Session Adapter Data Generation
        print("\nüìä TEST 1: Enhanced Session Adapter Data Generation")
        enhanced_events = self._test_enhanced_session_adapter()
        
        # Test 2: Dictionary Event Format Validation
        print("\nüîç TEST 2: Dictionary Event Format Validation")
        self._test_dictionary_event_format(enhanced_events)
        
        # Test 3: Lattice Mapper Integration (Critical Test)
        print("\nüó∫Ô∏è TEST 3: Lattice Mapper Integration (Critical)")
        lattice_dataset = self._test_lattice_mapper_integration(enhanced_events)
        
        # Test 4: Coordinate Mapping Validation
        print("\nüìç TEST 4: Coordinate Mapping Validation")
        self._test_coordinate_mapping(lattice_dataset)
        
        # Test 5: Hot Zone Detection
        print("\nüî• TEST 5: Hot Zone Detection")
        self._test_hot_zone_detection(lattice_dataset)
        
        # Test 6: Connection Network Analysis
        print("\nüï∏Ô∏è TEST 6: Connection Network Analysis")
        self._test_connection_network(lattice_dataset)
        
        # Test 7: Performance Validation
        print("\n‚ö° TEST 7: Performance Validation")
        self._test_performance_requirements()
        
        # Final Results
        self._display_final_results(lattice_dataset)
    
    def _test_enhanced_session_adapter(self) -> list[dict]:
        """Test Enhanced Session Adapter event generation"""
        
        try:
            # Create sample enhanced session data
            sample_session = {
                'session_metadata': {
                    'session_name': 'test_session_2025_08_15',
                    'session_date': '2025-08-15',
                    'session_type': 'PM'
                },
                'session_liquidity_events': [
                    {
                        'event_time': '14:35:00',
                        'event_type': 'fvg_formation',
                        'price': 23162.25,
                        'magnitude': 0.85,
                        'session_minute': 35.0
                    },
                    {
                        'event_time': '14:50:00',
                        'event_type': 'liquidity_sweep',
                        'price': 23180.50,
                        'magnitude': 0.72,
                        'session_minute': 50.0
                    },
                    {
                        'event_time': '15:15:00',
                        'event_type': 'expansion_phase',
                        'price': 23195.75,
                        'magnitude': 0.68,
                        'session_minute': 75.0
                    }
                ],
                'price_movements': [
                    {'time': '14:30:00', 'price': 23160.0, 'event_context': 'session_open'},
                    {'time': '14:35:00', 'price': 23162.25, 'event_context': 'fvg_40_zone'},
                    {'time': '14:50:00', 'price': 23180.50, 'event_context': 'sweep_completion'},
                    {'time': '15:15:00', 'price': 23195.75, 'event_context': 'expansion_continuation'}
                ]
            }
            
            # Test adapter conversion
            adapted_events = self.adapter.adapt_enhanced_session(sample_session)
            
            # Create multiple test events to simulate 2,888 events
            enhanced_events = []
            for i in range(50):  # Create 50 test events for comprehensive testing
                for base_event in adapted_events['events']:
                    test_event = base_event.copy()
                    test_event['event_id'] = f"test_event_{i}_{len(enhanced_events)}"
                    test_event['session_name'] = f"test_session_{i % 10}"
                    test_event['session_minute'] = (i * 2.5) % 180  # Spread across session
                    test_event['relative_cycle_position'] = (i * 0.02) % 1.0
                    enhanced_events.append(test_event)
            
            self.test_results['total_events_processed'] = len(enhanced_events)
            print(f"‚úÖ Enhanced Session Adapter: {len(enhanced_events)} events generated")
            print("   Event format: Dictionary-based (Enhanced Session Adapter format)")
            print(f"   Sample event keys: {list(enhanced_events[0].keys())}")
            
            self.test_results['tests_passed'] += 1
            return enhanced_events
            
        except Exception as e:
            print(f"‚ùå Enhanced Session Adapter test failed: {e}")
            self.test_results['tests_failed'] += 1
            return []
    
    def _test_dictionary_event_format(self, events: list[dict]):
        """Test dictionary event format compatibility"""
        
        try:
            # Validate event structure
            required_fields = ['event_type', 'event_family', 'timeframe', 'session_name']
            
            valid_events = 0
            for event in events:
                if all(field in event for field in required_fields):
                    valid_events += 1
            
            print(f"‚úÖ Dictionary Format Validation: {valid_events}/{len(events)} events valid")
            print(f"   Required fields present: {required_fields}")
            print("   Format compatibility: Enhanced Session Adapter ‚Üî Lattice Mapper")
            
            self.test_results['tests_passed'] += 1
            
        except Exception as e:
            print(f"‚ùå Dictionary format validation failed: {e}")
            self.test_results['tests_failed'] += 1
    
    def _test_lattice_mapper_integration(self, events: list[dict]):
        """Critical test: Lattice Mapper integration with dictionary events"""
        
        print("   üö® CRITICAL TEST: This validates the KeyError fixes")
        
        start_time = time.time()
        lattice_dataset = None
        
        try:
            # Attempt lattice mapping (this was failing before the fix)
            lattice_dataset = self.mapper.map_events_to_lattice(events)
            
            processing_time = time.time() - start_time
            
            # Validate results
            nodes_created = len(lattice_dataset.nodes)
            connections_created = len(lattice_dataset.connections)
            hot_zones_detected = len(lattice_dataset.hot_zones)
            
            self.test_results['nodes_created'] = nodes_created
            self.test_results['connections_created'] = connections_created
            self.test_results['hot_zones_detected'] = hot_zones_detected
            self.test_results['performance_metrics']['lattice_mapping_time'] = processing_time
            
            print("‚úÖ Lattice Mapper Integration: SUCCESS")
            print(f"   Events processed: {len(events)}")
            print(f"   Nodes created: {nodes_created}")
            print(f"   Connections created: {connections_created}")
            print(f"   Hot zones detected: {hot_zones_detected}")
            print(f"   Processing time: {processing_time:.3f} seconds")
            print(f"   KeyError count: {self.test_results['keyerror_count']} (TARGET: 0)")
            
            if processing_time < 5.0:  # IRONFORGE performance standard
                print("‚úÖ Performance: Within IRONFORGE <5s standard")
            else:
                print("‚ö†Ô∏è Performance: Exceeds 5s standard")
            
            self.test_results['tests_passed'] += 1
            return lattice_dataset
            
        except KeyError as e:
            self.test_results['keyerror_count'] += 1
            print(f"‚ùå CRITICAL FAILURE: KeyError occurred: {e}")
            print("   This indicates the defensive coding fix didn't work completely")
            self.test_results['tests_failed'] += 1
            return None
            
        except Exception as e:
            print(f"‚ùå Lattice Mapper Integration failed: {e}")
            self.test_results['tests_failed'] += 1
            return None
    
    def _test_coordinate_mapping(self, lattice_dataset):
        """Test coordinate mapping accuracy"""
        
        if not lattice_dataset:
            print("‚ùå Coordinate mapping test skipped (no dataset)")
            self.test_results['tests_failed'] += 1
            return
        
        try:
            # Validate coordinate ranges
            valid_coordinates = 0
            total_nodes = len(lattice_dataset.nodes)
            
            for _node_id, node in lattice_dataset.nodes.items():
                coord = node.coordinate
                
                # Check coordinate bounds
                if (0 <= coord.timeframe_level <= 7 and
                    0.0 <= coord.cycle_position <= 1.0 and
                    coord.absolute_timeframe is not None):
                    valid_coordinates += 1
            
            mapping_accuracy = (valid_coordinates / total_nodes) * 100 if total_nodes > 0 else 0
            
            print(f"‚úÖ Coordinate Mapping: {mapping_accuracy:.1f}% accuracy")
            print(f"   Valid coordinates: {valid_coordinates}/{total_nodes}")
            print("   Timeframe levels: 0-7 (monthly to 1m)")
            print("   Cycle positions: 0.0-1.0 (0% to 100%)")
            
            self.test_results['tests_passed'] += 1
            
        except Exception as e:
            print(f"‚ùå Coordinate mapping test failed: {e}")
            self.test_results['tests_failed'] += 1
    
    def _test_hot_zone_detection(self, lattice_dataset):
        """Test hot zone detection functionality"""
        
        if not lattice_dataset:
            print("‚ùå Hot zone detection test skipped (no dataset)")
            self.test_results['tests_failed'] += 1
            return
        
        try:
            hot_zones = lattice_dataset.hot_zones
            
            if hot_zones:
                print(f"‚úÖ Hot Zone Detection: {len(hot_zones)} zones detected")
                for zone_id, zone in list(hot_zones.items())[:3]:  # Show first 3
                    print(f"   {zone_id}: {zone.total_events} events, density {zone.event_density:.2f}")
            else:
                print("‚ÑπÔ∏è Hot Zone Detection: No zones detected (normal for small test dataset)")
            
            self.test_results['tests_passed'] += 1
            
        except Exception as e:
            print(f"‚ùå Hot zone detection test failed: {e}")
            self.test_results['tests_failed'] += 1
    
    def _test_connection_network(self, lattice_dataset):
        """Test connection network analysis"""
        
        if not lattice_dataset:
            print("‚ùå Connection network test skipped (no dataset)")
            self.test_results['tests_failed'] += 1
            return
        
        try:
            connections = lattice_dataset.connections
            
            if connections:
                # Analyze connection types
                connection_types = {}
                for conn in connections.values():
                    conn_type = conn.connection_type
                    connection_types[conn_type] = connection_types.get(conn_type, 0) + 1
                
                print(f"‚úÖ Connection Network: {len(connections)} connections created")
                for conn_type, count in connection_types.items():
                    print(f"   {conn_type}: {count} connections")
            else:
                print("‚ÑπÔ∏è Connection Network: No connections created (normal for small test dataset)")
            
            self.test_results['tests_passed'] += 1
            
        except Exception as e:
            print(f"‚ùå Connection network test failed: {e}")
            self.test_results['tests_failed'] += 1
    
    def _test_performance_requirements(self):
        """Test IRONFORGE performance requirements"""
        
        try:
            lattice_time = self.test_results['performance_metrics'].get('lattice_mapping_time', 0)
            
            # IRONFORGE standard: <5s execution time
            if lattice_time < 5.0:
                print(f"‚úÖ Performance Requirements: {lattice_time:.3f}s (< 5s IRONFORGE standard)")
                self.test_results['tests_passed'] += 1
            else:
                print(f"‚ö†Ô∏è Performance Requirements: {lattice_time:.3f}s (exceeds 5s standard)")
                self.test_results['tests_failed'] += 1
            
        except Exception as e:
            print(f"‚ùå Performance test failed: {e}")
            self.test_results['tests_failed'] += 1
    
    def _display_final_results(self, lattice_dataset):
        """Display comprehensive test results"""
        
        print("\n" + "üéØ FINAL TEST RESULTS" + "\n" + "=" * 60)
        
        total_tests = self.test_results['tests_passed'] + self.test_results['tests_failed']
        pass_rate = (self.test_results['tests_passed'] / total_tests) * 100 if total_tests > 0 else 0
        
        print("üìä Test Summary:")
        print(f"   Tests passed: {self.test_results['tests_passed']}")
        print(f"   Tests failed: {self.test_results['tests_failed']}")
        print(f"   Pass rate: {pass_rate:.1f}%")
        
        print("\nüó∫Ô∏è Lattice Mapping Results:")
        print(f"   Events processed: {self.test_results['total_events_processed']}")
        print(f"   KeyError count: {self.test_results['keyerror_count']} (TARGET: 0)")
        print(f"   Nodes created: {self.test_results['nodes_created']}")
        print(f"   Connections created: {self.test_results['connections_created']}")
        print(f"   Hot zones detected: {self.test_results['hot_zones_detected']}")
        
        # Critical success criteria
        critical_success = (
            self.test_results['keyerror_count'] == 0 and
            self.test_results['total_events_processed'] > 0 and
            self.test_results['nodes_created'] > 0
        )
        
        if critical_success:
            print("\n‚úÖ INTEGRATION TEST PASSED")
            print("   Enhanced Session Adapter ‚Üí Lattice Mapper pipeline operational")
            print("   KeyError issues resolved")
            print("   Ready for full 2,888 event processing")
        else:
            print("\n‚ùå INTEGRATION TEST FAILED")
            print("   KeyErrors still present or no events processed")
            print("   Additional debugging required")
        
        # Export test results
        self._export_test_results(lattice_dataset)
    
    def _export_test_results(self, lattice_dataset):
        """Export test results and lattice dataset"""
        
        try:
            # Export test results
            test_results_path = Path("/Users/jack/IRONFORGE/test_results_lattice_integration.json")
            with open(test_results_path, 'w') as f:
                json.dump(self.test_results, f, indent=2)
            
            print("\nüìÅ Test Results Exported:")
            print(f"   {test_results_path}")
            
            # Export lattice dataset if successful
            if lattice_dataset:
                dataset_path = Path("/Users/jack/IRONFORGE/deliverables/lattice_dataset/test_lattice_dataset.json")
                dataset_path.parent.mkdir(parents=True, exist_ok=True)
                export_path = self.mapper.export_lattice_dataset(lattice_dataset, str(dataset_path))
                print(f"   {export_path}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Export failed: {e}")

def main():
    """Run the integration test"""
    test = LatticeIntegrationTest()
    test.run_comprehensive_test()

if __name__ == "__main__":
    main()