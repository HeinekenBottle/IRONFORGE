{
  "engines": {
    "analysis": {
      "description": "Pattern analysis and session adaptation components",
      "components": [
        {
          "name": "extract_lattice_summary",
          "file": "extract_lattice_summary.py",
          "primary_classes": [],
          "primary_functions": [
            "extract_lattice_summary"
          ],
          "patterns": [],
          "lines_of_code": 162,
          "complexity": 19,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Extract and display key findings from global lattice results...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "temporal_correlator",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "primary_classes": [
            "CorrelationResult",
            "TemporalCorrelationEngine",
            "SequencePatternAnalyzer",
            "HTFEvent",
            "HTFIntensity",
            "HTFMasterController",
            "CascadeType",
            "MockEvent"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 484,
          "complexity": 57,
          "class_count": 8,
          "function_count": 17,
          "docstring": "Temporal Correlator - Extracted from cascade classifier for modular integration\nHandles prediction-validation correlation and sequence analysis...",
          "imports": 9,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "__init__",
          "file": "ironforge/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 15,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Archaeological Discovery System\nPackage version and main exports...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "broad_spectrum_archaeology",
          "file": "ironforge/analysis/broad_spectrum_archaeology.py",
          "primary_classes": [
            "BroadSpectrumArchaeology"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 49,
          "complexity": 3,
          "class_count": 1,
          "function_count": 2,
          "docstring": "Broad Spectrum Archaeology\nComprehensive pattern discovery across market sessions...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "enhanced_session_adapter",
          "file": "ironforge/analysis/enhanced_session_adapter.py",
          "primary_classes": [
            "EnhancedSessionAdapter"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 49,
          "complexity": 3,
          "class_count": 1,
          "function_count": 2,
          "docstring": "Enhanced Session Adapter\nAdapts session data for archaeological analysis...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "timeframe_lattice_mapper",
          "file": "ironforge/analysis/timeframe_lattice_mapper.py",
          "primary_classes": [
            "TimeframeLatticeMapper"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 245,
          "complexity": 24,
          "class_count": 1,
          "function_count": 6,
          "docstring": "Timeframe Lattice Mapper\nPattern analysis component for timeframe relationships...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "scoring",
          "file": "ironforge/confluence/scoring.py",
          "primary_classes": [],
          "primary_functions": [
            "score_confluence",
            "score_session"
          ],
          "patterns": [],
          "lines_of_code": 62,
          "complexity": 4,
          "class_count": 0,
          "function_count": 2,
          "docstring": "",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/contracts/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 28,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Contracts\n===================\n\nCanonical data contracts and taxonomy definitions for archaeological discovery....",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "cli",
          "file": "ironforge/sdk/cli.py",
          "primary_classes": [],
          "primary_functions": [
            "cmd_discover",
            "cmd_score",
            "cmd_validate",
            "cmd_report",
            "cmd_prep_shards",
            "cmd_status",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 241,
          "complexity": 38,
          "class_count": 0,
          "function_count": 9,
          "docstring": "",
          "imports": 16,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/semantic_engine/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 11,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Semantic Engine  \n=========================\n\nSemantic confluence scoring for archaeological significance assessment.\nThin re-export layer for canonical import paths....",
          "imports": 1,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/temporal_engine/__init__.py",
          "primary_classes": [],
          "primary_functions": [
            "run_discovery"
          ],
          "patterns": [],
          "lines_of_code": 25,
          "complexity": 1,
          "class_count": 0,
          "function_count": 1,
          "docstring": "IRONFORGE Temporal Engine\n========================\n\nTemporal discovery engine for archaeological pattern discovery via TGAT.\nThin re-export layer for canonical import paths....",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "run_fpfvg_network_analysis",
          "file": "run_fpfvg_network_analysis.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 346,
          "complexity": 38,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üîÑ IRONFORGE FPFVG Network Analysis Execution (Step 3A)\n======================================================\n\nMicro Mechanism Analysis: Prove FVGs form networks whose re-deliveries align with Theory ...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "run_fpfvg_network_analysis_simple",
          "file": "run_fpfvg_network_analysis_simple.py",
          "primary_classes": [
            "SimpleFPFVGAnalyzer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 454,
          "complexity": 54,
          "class_count": 1,
          "function_count": 16,
          "docstring": "üîÑ IRONFORGE FPFVG Network Analysis (Step 3A) - Simplified\n==========================================================\n\nFocused implementation to prove FVG redelivery alignment with Theory B zones and P...",
          "imports": 12,
          "decorators": []
        },
        {
          "name": "run_fpfvg_redelivery_lattice",
          "file": "run_fpfvg_redelivery_lattice.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 241,
          "complexity": 22,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üîÑ IRONFORGE FPFVG Redelivery Network Lattice Execution\n======================================================\n\nTheory B Testing: \"Zones Know Their Completion\"\nTests whether FVG formations position the...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "run_global_lattice",
          "file": "run_global_lattice.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 145,
          "complexity": 14,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üåê IRONFORGE Global Lattice Execution\n====================================\n\nExecutes the comprehensive Monthly‚Üí1m global lattice build across all enhanced sessions.\nThis is STEP 1 of the discovery fram...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "run_specialized_lattice",
          "file": "run_specialized_lattice.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 250,
          "complexity": 25,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üß© IRONFORGE Specialized Lattice Execution\n==========================================\n\nSTEP 3: Builds specialized lattice views based on terrain analysis findings.\nPriority 1: NY PM Archaeological Belt...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "run_terrain_analysis",
          "file": "run_terrain_analysis.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 189,
          "complexity": 20,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üîç IRONFORGE Terrain Analysis Execution\n======================================\n\nSTEP 2: Analyzes the global lattice terrain to identify hot zones and cascade patterns.\nBased on the successful global la...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "run_weekly_daily_cascade_lattice",
          "file": "run_weekly_daily_cascade_lattice.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 307,
          "complexity": 43,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üìà IRONFORGE Weekly‚ÜíDaily Liquidity Sweep Cascade Lattice Execution\n==================================================================\n\nMacro-Level Cascade Pattern Discovery\nMaps higher timeframe (Week...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "run_weekly_daily_sweep_cascade_step_3b_refined",
          "file": "run_weekly_daily_sweep_cascade_step_3b_refined.py",
          "primary_classes": [
            "RefinedCascadeAnalyzer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 436,
          "complexity": 38,
          "class_count": 1,
          "function_count": 8,
          "docstring": "üìà IRONFORGE Weekly‚ÜíDaily Liquidity Sweep Cascade Analysis (Step 3B) - REFINED\n==============================================================================\n\nRefined implementation with lowered detect...",
          "imports": 9,
          "decorators": []
        },
        {
          "name": "run_working_cascade_analysis",
          "file": "run_working_cascade_analysis.py",
          "primary_classes": [
            "WorkingSweepEvent",
            "WorkingCascadeLink",
            "WorkingCascadeAnalyzer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 541,
          "complexity": 59,
          "class_count": 3,
          "function_count": 18,
          "docstring": "üéØ IRONFORGE Working Cascade Analysis\n====================================\n\nStreamlined implementation based on actual data structure findings.\nUses proven patterns from simple_threshold_test.py to get...",
          "imports": 12,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "analyze_concrete_patterns",
          "file": "scripts/analysis/analyze_concrete_patterns.py",
          "primary_classes": [],
          "primary_functions": [
            "analyze_actual_events_by_subpattern",
            "analyze_market_mechanics",
            "analyze_specific_examples",
            "decode_price_levels",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 344,
          "complexity": 56,
          "class_count": 0,
          "function_count": 5,
          "docstring": "Concrete Analysis: What Do These Sub-Patterns Actually Mean?\n===========================================================\nMove beyond vague descriptions to specific market mechanics...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "analyze_nypm_patterns",
          "file": "scripts/analysis/analyze_nypm_patterns.py",
          "primary_classes": [],
          "primary_functions": [
            "analyze_nypm_patterns"
          ],
          "patterns": [],
          "lines_of_code": 135,
          "complexity": 18,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Analyze NY PM session patterns from IRONFORGE discoveries...",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "bridge_node_mapper",
          "file": "scripts/analysis/bridge_node_mapper.py",
          "primary_classes": [
            "BridgeNodeMapper"
          ],
          "primary_functions": [
            "main",
            "convert_numpy_types"
          ],
          "patterns": [],
          "lines_of_code": 545,
          "complexity": 82,
          "class_count": 1,
          "function_count": 15,
          "docstring": "IRONFORGE Bridge Node Mapper\n============================\n\nMaps cascade pathways from HTF events ‚Üí PM belt events to identify:\n1. Whether PM belt events are terminal nodes or relay points\n2. Which HTF...",
          "imports": 12,
          "decorators": []
        },
        {
          "name": "comprehensive_discovery_report",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "primary_classes": [],
          "primary_functions": [
            "analyze_all_sessions",
            "analyze_single_session",
            "create_time_clusters",
            "extract_session_type",
            "analyze_temporal_patterns",
            "analyze_pattern_quality",
            "analyze_discovered_patterns",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 356,
          "complexity": 53,
          "class_count": 0,
          "function_count": 8,
          "docstring": "Comprehensive IRONFORGE Discovery Report\n========================================\nDeep analysis of what the enhanced system with Simple Event-Time Clustering discovers...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "decode_subpattern_findings",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "primary_classes": [],
          "primary_functions": [
            "decode_feature_7",
            "decode_feature_clusters",
            "decode_sub_pattern_0",
            "decode_sub_pattern_1",
            "decode_sub_pattern_2",
            "synthesize_discovery",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 248,
          "complexity": 8,
          "class_count": 0,
          "function_count": 7,
          "docstring": "Decode Sub-Pattern Findings - What is Feature 7 and Sub-Pattern 0?\n=================================================================\nDecode the actual meaning of the discovered sub-patterns and key fe...",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "enrichment_analyzer",
          "file": "scripts/analysis/enrichment_analyzer.py",
          "primary_classes": [
            "EnrichmentAnalyzer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 370,
          "complexity": 40,
          "class_count": 1,
          "function_count": 11,
          "docstring": "IRONFORGE Enrichment Analyzer\n=============================\n\nTests the hypothesis: Do events in the 14:35-38pm PM belt disproportionately \nmap to specific lattice zones (like the 40% dimensional ancho...",
          "imports": 10,
          "decorators": []
        },
        {
          "name": "explore_discoveries",
          "file": "scripts/analysis/explore_discoveries.py",
          "primary_classes": [],
          "primary_functions": [
            "load_time_patterns_from_graphs",
            "analyze_discovered_patterns",
            "explore_time_clustering_insights",
            "show_session_insights",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 259,
          "complexity": 37,
          "class_count": 0,
          "function_count": 5,
          "docstring": "Explore IRONFORGE Discovery Results with Time Pattern Intelligence\n================================================================\nSee what the Simple Event-Time Clustering + Cross-TF Mapping reveals...",
          "imports": 6,
          "decorators": []
        },
        {
          "name": "investigate_cross_session_synchronization",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "primary_classes": [],
          "primary_functions": [
            "extract_event_timing_data",
            "build_synchronization_matrix",
            "identify_synchronized_time_slots",
            "analyze_temporal_patterns",
            "test_synchronization_hypothesis",
            "create_synchronization_visualization",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 440,
          "complexity": 55,
          "class_count": 0,
          "function_count": 7,
          "docstring": "RANK 1: Cross-Session Temporal Synchronization Investigation\n===========================================================\nDiscover if events cluster at consistent intraday times across different calend...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "investigate_htf_structural_inheritance",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "primary_classes": [],
          "primary_functions": [
            "extract_htf_ltf_relationships",
            "get_dominant_event",
            "analyze_htf_ltf_correlations",
            "discover_htf_inheritance_rules",
            "analyze_event_type_htf_preferences",
            "test_htf_coherence_hypothesis",
            "create_htf_inheritance_visualization",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 784,
          "complexity": 78,
          "class_count": 0,
          "function_count": 8,
          "docstring": "RANK 6: Cross-Timeframe Structural Inheritance Investigation\n===========================================================\nInvestigating how events inherit structural properties from higher timeframes,\n...",
          "imports": 10,
          "decorators": []
        },
        {
          "name": "investigate_pattern_subarchitecture",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "primary_classes": [],
          "primary_functions": [
            "load_tgat_patterns",
            "load_feature_vectors",
            "analyze_pattern_archetypes",
            "discover_sub_patterns",
            "analyze_clusters",
            "calculate_silhouette_score",
            "visualize_sub_patterns",
            "characterize_sub_patterns",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 345,
          "complexity": 30,
          "class_count": 0,
          "function_count": 9,
          "docstring": "TGAT Pattern Sub-Architecture Investigation\n==========================================\nDiscover hidden sub-patterns within the 3 main TGAT archetypes using 38D feature space analysis...",
          "imports": 12,
          "decorators": []
        },
        {
          "name": "phase2_feature_pipeline_enhancement",
          "file": "scripts/analysis/phase2_feature_pipeline_enhancement.py",
          "primary_classes": [
            "FeaturePipelineEnhancer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 527,
          "complexity": 50,
          "class_count": 1,
          "function_count": 9,
          "docstring": "IRONFORGE Phase 2: Feature Pipeline Enhancement\n============================================\n\nTGAT Model Quality Recovery - Phase 2 Implementation\n\nCONTEXT: Phase 1 breakthrough confirmed TGAT archite...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "phase4_full_scale_archaeological_discovery",
          "file": "scripts/analysis/phase4_full_scale_archaeological_discovery.py",
          "primary_classes": [
            "FullScaleArchaeologicalDiscovery"
          ],
          "primary_functions": [
            "run_phase4a_full_scale"
          ],
          "patterns": [],
          "lines_of_code": 325,
          "complexity": 20,
          "class_count": 1,
          "function_count": 6,
          "docstring": "Phase 4a: Full Scale Archaeological Discovery\n============================================\nRun TGAT at full scale on all clean sessions with full features.\nTest pattern discovery on long runs and mult...",
          "imports": 10,
          "decorators": []
        },
        {
          "name": "phase4b_attention_head_analysis",
          "file": "scripts/analysis/phase4b_attention_head_analysis.py",
          "primary_classes": [
            "AttentionHeadAnalyzer"
          ],
          "primary_functions": [
            "run_phase4b_attention_analysis",
            "attention_hook",
            "hook_fn"
          ],
          "patterns": [],
          "lines_of_code": 430,
          "complexity": 53,
          "class_count": 1,
          "function_count": 13,
          "docstring": "Phase 4b: 4-Head Attention Verification\n======================================\nVerify that each of the 4 TGAT attention heads discovers different\npattern archetypes, not all focusing on the same links...",
          "imports": 12,
          "decorators": []
        },
        {
          "name": "phase4b_attention_verification",
          "file": "scripts/analysis/phase4b_attention_verification.py",
          "primary_classes": [
            "AttentionHeadAnalyzer"
          ],
          "primary_functions": [
            "run_phase4b_attention_analysis"
          ],
          "patterns": [],
          "lines_of_code": 336,
          "complexity": 35,
          "class_count": 1,
          "function_count": 8,
          "docstring": "Phase 4b: 4-Head Attention Verification\n======================================\nVerify that each of the 4 TGAT attention heads discovers different\npattern archetypes, not all focusing on the same links...",
          "imports": 11,
          "decorators": []
        },
        {
          "name": "phase4c_temporal_resonance",
          "file": "scripts/analysis/phase4c_temporal_resonance.py",
          "primary_classes": [
            "TemporalResonanceAnalyzer"
          ],
          "primary_functions": [
            "run_phase4c_temporal_resonance",
            "extract_date"
          ],
          "patterns": [],
          "lines_of_code": 592,
          "complexity": 83,
          "class_count": 1,
          "function_count": 9,
          "docstring": "Phase 4c: Temporal Resonance Testing (Cross-Session Links)\n=========================================================\nProve IRONFORGE discovers permanent, cross-session structures.\nBuild multi-session ...",
          "imports": 12,
          "decorators": []
        },
        {
          "name": "phase5_archaeological_discovery_validation",
          "file": "scripts/analysis/phase5_archaeological_discovery_validation.py",
          "primary_classes": [
            "Phase5ArchaeologicalValidator"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 460,
          "complexity": 26,
          "class_count": 1,
          "function_count": 9,
          "docstring": "Phase 5: Archaeological Discovery Validation\n==========================================\nTest TGAT model pattern discovery capability on authentic enhanced features \nafter Phase 2 decontamination to va...",
          "imports": 9,
          "decorators": []
        },
        {
          "name": "phase5_direct_tgat_validation",
          "file": "scripts/analysis/phase5_direct_tgat_validation.py",
          "primary_classes": [
            "Phase5DirectTGATValidator"
          ],
          "primary_functions": [
            "make_serializable",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 523,
          "complexity": 56,
          "class_count": 1,
          "function_count": 9,
          "docstring": "Phase 5: Direct TGAT Discovery Validation\n========================================\nDirect test of TGAT archaeological discovery on enhanced sessions\nto validate pattern quality vs contaminated baselin...",
          "imports": 13,
          "decorators": []
        },
        {
          "name": "phase5_enhanced_session_validation",
          "file": "scripts/analysis/phase5_enhanced_session_validation.py",
          "primary_classes": [],
          "primary_functions": [
            "create_mock_graph_from_session",
            "test_enhanced_session_pattern_discovery",
            "analyze_pattern_quality_improvement",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 258,
          "complexity": 25,
          "class_count": 0,
          "function_count": 4,
          "docstring": "Phase 5: Enhanced Session TGAT Validation\n=========================================\nTest TGAT pattern discovery on enhanced sessions and validate quality improvement....",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "process_all_sessions",
          "file": "scripts/analysis/process_all_sessions.py",
          "primary_classes": [],
          "primary_functions": [
            "process_all_sessions",
            "analyze_all_time_patterns"
          ],
          "patterns": [],
          "lines_of_code": 171,
          "complexity": 18,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Process ALL Sessions with Simple Event-Time Clustering + Cross-TF Mapping\n=========================================================================\nComplete analysis of the entire dataset with tempora...",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "quick_pattern_discovery",
          "file": "scripts/analysis/quick_pattern_discovery.py",
          "primary_classes": [
            "QuickPatternDiscovery"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 210,
          "complexity": 15,
          "class_count": 1,
          "function_count": 3,
          "docstring": "IRONFORGE Quick Pattern Discovery\n=================================\n\nFast pattern discovery script for immediate insights.\nAnalyzes top sessions and shows key patterns quickly.\n\nUsage:\n    python3 qui...",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "real_pattern_finder",
          "file": "scripts/analysis/real_pattern_finder.py",
          "primary_classes": [],
          "primary_functions": [
            "extract_price_from_node_feature",
            "find_real_patterns"
          ],
          "patterns": [],
          "lines_of_code": 114,
          "complexity": 15,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Real Pattern Finder - Finds ACTUAL cross-timeframe patterns in IRONFORGE graphs\nNo embeddings, no similarities, just real market relationships...",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "run_archaeology_demonstration",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "primary_classes": [
            "DemoTimeframe",
            "DemoEventType",
            "DemoSessionPhase",
            "DemoArchaeologicalEvent"
          ],
          "primary_functions": [
            "setup_demonstration_environment",
            "generate_synthetic_archaeological_events",
            "demonstrate_lattice_mapping",
            "demonstrate_temporal_clustering",
            "demonstrate_structural_analysis",
            "create_demonstration_visualizations",
            "generate_demonstration_report",
            "main",
            "find_cascade_paths"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 1258,
          "complexity": 92,
          "class_count": 4,
          "function_count": 9,
          "docstring": "IRONFORGE Archaeological Discovery Demonstration\n===============================================\n\nComplete demonstration of the broad-spectrum market archaeology system\nusing enhanced synthetic data t...",
          "imports": 14,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "run_contaminated_session_enhancement",
          "file": "scripts/analysis/run_contaminated_session_enhancement.py",
          "primary_classes": [],
          "primary_functions": [
            "get_contaminated_sessions",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 75,
          "complexity": 12,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Run Phase 2 Enhancement on Contaminated Sessions\n==============================================\n\nTarget the 33 contaminated TGAT-ready sessions that need decontamination....",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "run_enhanced_adapter_demonstration",
          "file": "scripts/analysis/run_enhanced_adapter_demonstration.py",
          "primary_classes": [
            "EnhancedAdapterDemo"
          ],
          "primary_functions": [
            "run_quick_demo",
            "run_full_demo",
            "run_integration_test"
          ],
          "patterns": [],
          "lines_of_code": 519,
          "complexity": 49,
          "class_count": 1,
          "function_count": 12,
          "docstring": "Enhanced Session Adapter Live Demonstration System\n==================================================\n\nDemonstrates the Enhanced Session Adapter with real IRONFORGE enhanced\nsessions, showing the dram...",
          "imports": 11,
          "decorators": []
        },
        {
          "name": "run_full_archaeology_discovery",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "primary_classes": [],
          "primary_functions": [
            "setup_production_environment",
            "discover_archaeological_phenomena",
            "generate_lattice_mapping",
            "analyze_temporal_patterns",
            "analyze_structural_relationships",
            "create_comprehensive_visualizations",
            "generate_executive_report",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 614,
          "complexity": 22,
          "class_count": 0,
          "function_count": 8,
          "docstring": "IRONFORGE Full Archaeological Discovery Workflow\n===============================================\n\nProduction workflow for running complete broad-spectrum market archaeology\non IRONFORGE's 57 enhanced ...",
          "imports": 16,
          "decorators": []
        },
        {
          "name": "run_full_scale_discovery",
          "file": "scripts/analysis/run_full_scale_discovery.py",
          "primary_classes": [],
          "primary_functions": [
            "run_full_scale_discovery"
          ],
          "patterns": [],
          "lines_of_code": 196,
          "complexity": 13,
          "class_count": 0,
          "function_count": 1,
          "docstring": "IRONFORGE Full-Scale Archaeological Discovery\n============================================\nRuns Sprint 2 discovery system on all 66 sessions to achieve 2,800+ pattern discoveries.\n\nFeatures:\n- 37D tem...",
          "imports": 10,
          "decorators": []
        },
        {
          "name": "run_full_session_analysis",
          "file": "scripts/analysis/run_full_session_analysis.py",
          "primary_classes": [
            "SessionAnalyzer"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 443,
          "complexity": 23,
          "class_count": 1,
          "function_count": 9,
          "docstring": "IRONFORGE Full Session Analysis\n===============================\n\nComprehensive analysis script to run IRONFORGE over all logged sessions\nand extract patterns, data, timing analysis, and generate visua...",
          "imports": 12,
          "decorators": []
        },
        {
          "name": "run_htf_orchestrator",
          "file": "scripts/analysis/run_htf_orchestrator.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 83,
          "complexity": 6,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Run IRONFORGE Orchestrator with PRICE RELATIVITY Enhanced Sessions\nDemonstrates permanent pattern discovery with structural relationships\n\nCRITICAL UPGRADE: Now uses price relativity features for perm...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "lattice_population_runner",
          "file": "scripts/utilities/lattice_population_runner.py",
          "primary_classes": [
            "LatticePopulationRunner"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 290,
          "complexity": 28,
          "class_count": 1,
          "function_count": 8,
          "docstring": "IRONFORGE Lattice Population Runner\n==================================\n\nProcesses all enhanced session events through the fixed TimeframeLatticeMapper\nto generate a comprehensive multi-timeframe latti...",
          "imports": 10,
          "decorators": []
        },
        {
          "name": "setup",
          "file": "setup.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 72,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Setup script for IRONFORGE Archaeological Discovery System...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "lattice_visualizer",
          "file": "visualizations/lattice_visualizer.py",
          "primary_classes": [
            "VisualizationConfig",
            "LatticeVisualizer"
          ],
          "primary_functions": [],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 986,
          "complexity": 64,
          "class_count": 2,
          "function_count": 10,
          "docstring": "IRONFORGE Lattice Visualizer\n============================\n\nInteractive visualization system for the timeframe √ó cycle-position lattice.\nCreates comprehensive visual representations of archaeological p...",
          "imports": 51,
          "decorators": [
            "dataclass"
          ]
        }
      ],
      "file_count": 51,
      "total_lines": 16588,
      "complexity_score": 1624,
      "key_classes": [
        {
          "name": "CorrelationResult",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": "Result from temporal correlation analysis..."
        },
        {
          "name": "TemporalCorrelationEngine",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": "Engine for correlating predictions with validation data across sequences..."
        },
        {
          "name": "SequencePatternAnalyzer",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": "Analyzer for detecting patterns in cascade sequences..."
        },
        {
          "name": "HTFEvent",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": "Higher Timeframe event..."
        },
        {
          "name": "HTFIntensity",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": "HTF intensity calculation result..."
        },
        {
          "name": "HTFMasterController",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": "Higher Timeframe Master Controller\n\nImplements fractal cascade architecture where HTF events serve a..."
        },
        {
          "name": "CascadeType",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": ""
        },
        {
          "name": "MockEvent",
          "file": "iron_core/mathematical/temporal_correlator.py",
          "docstring": ""
        },
        {
          "name": "BroadSpectrumArchaeology",
          "file": "ironforge/analysis/broad_spectrum_archaeology.py",
          "docstring": "Comprehensive archaeological analysis across multiple sessions\nDiscovers broad spectrum patterns and..."
        },
        {
          "name": "EnhancedSessionAdapter",
          "file": "ironforge/analysis/enhanced_session_adapter.py",
          "docstring": "Adapts raw session data for enhanced archaeological analysis\nProvides session context and enhancemen..."
        },
        {
          "name": "TimeframeLatticeMapper",
          "file": "ironforge/analysis/timeframe_lattice_mapper.py",
          "docstring": "Maps discovered patterns across different timeframes\nAnalyzes multi-timeframe pattern relationships..."
        },
        {
          "name": "SimpleFPFVGAnalyzer",
          "file": "run_fpfvg_network_analysis_simple.py",
          "docstring": "Simplified FPFVG network analyzer focused on key statistical tests..."
        },
        {
          "name": "RefinedCascadeAnalyzer",
          "file": "run_weekly_daily_sweep_cascade_step_3b_refined.py",
          "docstring": "Enhanced cascade analyzer with refined detection thresholds..."
        },
        {
          "name": "WorkingSweepEvent",
          "file": "run_working_cascade_analysis.py",
          "docstring": "Streamlined sweep event based on actual data patterns..."
        },
        {
          "name": "WorkingCascadeLink",
          "file": "run_working_cascade_analysis.py",
          "docstring": "Streamlined cascade link..."
        },
        {
          "name": "WorkingCascadeAnalyzer",
          "file": "run_working_cascade_analysis.py",
          "docstring": "Streamlined cascade analyzer using proven data patterns..."
        },
        {
          "name": "BridgeNodeMapper",
          "file": "scripts/analysis/bridge_node_mapper.py",
          "docstring": "Maps HTF ‚Üí PM cascade pathways and bridge node relationships..."
        },
        {
          "name": "EnrichmentAnalyzer",
          "file": "scripts/analysis/enrichment_analyzer.py",
          "docstring": "Analyzes statistical enrichment of PM belt events in lattice zones..."
        },
        {
          "name": "FeaturePipelineEnhancer",
          "file": "scripts/analysis/phase2_feature_pipeline_enhancement.py",
          "docstring": "Phase 2 Feature Pipeline Enhancement for TGAT Model Quality Recovery\n\nReplaces artificial default va..."
        },
        {
          "name": "FullScaleArchaeologicalDiscovery",
          "file": "scripts/analysis/phase4_full_scale_archaeological_discovery.py",
          "docstring": "Full scale archaeological discovery with no session limits or chunking...."
        },
        {
          "name": "AttentionHeadAnalyzer",
          "file": "scripts/analysis/phase4b_attention_head_analysis.py",
          "docstring": "Analyze TGAT attention heads to verify archeological pattern specialization...."
        },
        {
          "name": "AttentionHeadAnalyzer",
          "file": "scripts/analysis/phase4b_attention_verification.py",
          "docstring": "Analyze TGAT attention heads to verify archeological pattern specialization...."
        },
        {
          "name": "TemporalResonanceAnalyzer",
          "file": "scripts/analysis/phase4c_temporal_resonance.py",
          "docstring": "Analyze temporal resonance across multiple sessions...."
        },
        {
          "name": "Phase5ArchaeologicalValidator",
          "file": "scripts/analysis/phase5_archaeological_discovery_validation.py",
          "docstring": "Phase 5 TGAT Archaeological Discovery Validation\nTests pattern discovery on authentic enhanced featu..."
        },
        {
          "name": "Phase5DirectTGATValidator",
          "file": "scripts/analysis/phase5_direct_tgat_validation.py",
          "docstring": "Direct TGAT validation without container dependencies..."
        },
        {
          "name": "QuickPatternDiscovery",
          "file": "scripts/analysis/quick_pattern_discovery.py",
          "docstring": "Fast pattern discovery for immediate insights..."
        },
        {
          "name": "DemoTimeframe",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "docstring": ""
        },
        {
          "name": "DemoEventType",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "docstring": ""
        },
        {
          "name": "DemoSessionPhase",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "docstring": ""
        },
        {
          "name": "DemoArchaeologicalEvent",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "docstring": "Enhanced synthetic archaeological event..."
        },
        {
          "name": "EnhancedAdapterDemo",
          "file": "scripts/analysis/run_enhanced_adapter_demonstration.py",
          "docstring": "Live demonstration system for Enhanced Session Adapter..."
        },
        {
          "name": "SessionAnalyzer",
          "file": "scripts/analysis/run_full_session_analysis.py",
          "docstring": "Comprehensive session analysis with pattern extraction and visualization..."
        },
        {
          "name": "LatticePopulationRunner",
          "file": "scripts/utilities/lattice_population_runner.py",
          "docstring": "Populates the complete IRONFORGE lattice with all available enhanced sessions..."
        },
        {
          "name": "VisualizationConfig",
          "file": "visualizations/lattice_visualizer.py",
          "docstring": "Configuration for visualization settings..."
        },
        {
          "name": "LatticeVisualizer",
          "file": "visualizations/lattice_visualizer.py",
          "docstring": "Comprehensive visualization system for market archaeology lattice..."
        }
      ],
      "public_interfaces": [
        {
          "name": "extract_lattice_summary",
          "file": "extract_lattice_summary.py",
          "parameters": 1,
          "docstring": "Extract key summary information from lattice file..."
        },
        {
          "name": "score_confluence",
          "file": "ironforge/confluence/scoring.py",
          "parameters": 4,
          "docstring": "Stub confluence scorer.\n\nCreates a simple dataframe with scores and writes it to a parquet file.\nRet..."
        },
        {
          "name": "score_session",
          "file": "ironforge/confluence/scoring.py",
          "parameters": 1,
          "docstring": "CLI-compatible wrapper for score_confluence..."
        },
        {
          "name": "cmd_discover",
          "file": "ironforge/sdk/cli.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "cmd_score",
          "file": "ironforge/sdk/cli.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "cmd_validate",
          "file": "ironforge/sdk/cli.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "cmd_report",
          "file": "ironforge/sdk/cli.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "cmd_prep_shards",
          "file": "ironforge/sdk/cli.py",
          "parameters": 8,
          "docstring": "Prepare Parquet shards from enhanced JSON sessions...."
        },
        {
          "name": "cmd_status",
          "file": "ironforge/sdk/cli.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "main",
          "file": "ironforge/sdk/cli.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "run_discovery",
          "file": "ironforge/temporal_engine/__init__.py",
          "parameters": 2,
          "docstring": "Stub function when discovery pipeline is not available..."
        },
        {
          "name": "main",
          "file": "run_fpfvg_network_analysis.py",
          "parameters": 0,
          "docstring": "Execute FPFVG Network Analysis (Step 3A)..."
        },
        {
          "name": "main",
          "file": "run_fpfvg_network_analysis_simple.py",
          "parameters": 0,
          "docstring": "Execute simplified FPFVG network analysis..."
        },
        {
          "name": "main",
          "file": "run_fpfvg_redelivery_lattice.py",
          "parameters": 0,
          "docstring": "Execute FPFVG Redelivery Network Lattice analysis..."
        },
        {
          "name": "main",
          "file": "run_global_lattice.py",
          "parameters": 0,
          "docstring": "Execute global lattice build..."
        },
        {
          "name": "main",
          "file": "run_specialized_lattice.py",
          "parameters": 0,
          "docstring": "Execute specialized lattice building for archaeological deep dive..."
        },
        {
          "name": "main",
          "file": "run_terrain_analysis.py",
          "parameters": 0,
          "docstring": "Execute terrain analysis for hot zones and cascades..."
        },
        {
          "name": "main",
          "file": "run_weekly_daily_cascade_lattice.py",
          "parameters": 0,
          "docstring": "Execute Weekly‚ÜíDaily Liquidity Sweep Cascade Lattice analysis..."
        },
        {
          "name": "main",
          "file": "run_weekly_daily_sweep_cascade_step_3b_refined.py",
          "parameters": 0,
          "docstring": "Execute REFINED Weekly‚ÜíDaily Liquidity Sweep Cascade Analysis (Step 3B)..."
        },
        {
          "name": "main",
          "file": "run_working_cascade_analysis.py",
          "parameters": 0,
          "docstring": "Execute working cascade analysis..."
        },
        {
          "name": "analyze_actual_events_by_subpattern",
          "file": "scripts/analysis/analyze_concrete_patterns.py",
          "parameters": 0,
          "docstring": "Analyze what actual semantic events occur in each sub-pattern..."
        },
        {
          "name": "analyze_market_mechanics",
          "file": "scripts/analysis/analyze_concrete_patterns.py",
          "parameters": 0,
          "docstring": "Analyze what these patterns mean in terms of actual market mechanics..."
        },
        {
          "name": "analyze_specific_examples",
          "file": "scripts/analysis/analyze_concrete_patterns.py",
          "parameters": 0,
          "docstring": "Look at specific examples of each sub-pattern..."
        },
        {
          "name": "decode_price_levels",
          "file": "scripts/analysis/analyze_concrete_patterns.py",
          "parameters": 0,
          "docstring": "Analyze what specific price levels and movements these patterns represent..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/analyze_concrete_patterns.py",
          "parameters": 0,
          "docstring": "Main concrete analysis..."
        },
        {
          "name": "analyze_nypm_patterns",
          "file": "scripts/analysis/analyze_nypm_patterns.py",
          "parameters": 0,
          "docstring": "Analyze discovered patterns specifically for NY PM sessions..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/bridge_node_mapper.py",
          "parameters": 0,
          "docstring": "Run bridge node analysis..."
        },
        {
          "name": "convert_numpy_types",
          "file": "scripts/analysis/bridge_node_mapper.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "analyze_all_sessions",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 0,
          "docstring": "Analyze all preserved sessions comprehensively..."
        },
        {
          "name": "analyze_single_session",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 2,
          "docstring": "Comprehensive analysis of a single session..."
        },
        {
          "name": "create_time_clusters",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 2,
          "docstring": "Create time clusters from events..."
        },
        {
          "name": "extract_session_type",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 1,
          "docstring": "Extract session type from session name..."
        },
        {
          "name": "analyze_temporal_patterns",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 1,
          "docstring": "Analyze temporal patterns across sessions..."
        },
        {
          "name": "analyze_pattern_quality",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 1,
          "docstring": "Analyze the quality and characteristics of discovered patterns..."
        },
        {
          "name": "analyze_discovered_patterns",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 0,
          "docstring": "Analyze the 500 patterns from TGAT discovery..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/comprehensive_discovery_report.py",
          "parameters": 0,
          "docstring": "Main analysis function..."
        },
        {
          "name": "decode_feature_7",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Decode what Feature 7 actually represents in the 47D feature vector..."
        },
        {
          "name": "decode_feature_clusters",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Decode the other significant features from the clustering..."
        },
        {
          "name": "decode_sub_pattern_0",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Decode what Sub-Pattern 0 actually represents..."
        },
        {
          "name": "decode_sub_pattern_1",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Decode what Sub-Pattern 1 represents..."
        },
        {
          "name": "decode_sub_pattern_2",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Decode what Sub-Pattern 2 represents..."
        },
        {
          "name": "synthesize_discovery",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Synthesize the complete discovery meaning..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/decode_subpattern_findings.py",
          "parameters": 0,
          "docstring": "Main analysis function..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/enrichment_analyzer.py",
          "parameters": 0,
          "docstring": "Run enrichment analysis..."
        },
        {
          "name": "load_time_patterns_from_graphs",
          "file": "scripts/analysis/explore_discoveries.py",
          "parameters": 0,
          "docstring": "Load time patterns from preserved graphs..."
        },
        {
          "name": "analyze_discovered_patterns",
          "file": "scripts/analysis/explore_discoveries.py",
          "parameters": 0,
          "docstring": "Load and analyze the 500 discovered patterns..."
        },
        {
          "name": "explore_time_clustering_insights",
          "file": "scripts/analysis/explore_discoveries.py",
          "parameters": 2,
          "docstring": "Analyze the time clustering discoveries..."
        },
        {
          "name": "show_session_insights",
          "file": "scripts/analysis/explore_discoveries.py",
          "parameters": 1,
          "docstring": "Show insights by session..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/explore_discoveries.py",
          "parameters": 0,
          "docstring": "Main exploration function..."
        },
        {
          "name": "extract_event_timing_data",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 0,
          "docstring": "Extract absolute time-of-day for each semantic event across all sessions..."
        },
        {
          "name": "build_synchronization_matrix",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 1,
          "docstring": "Build co-occurrence matrix: Time_Bin[i] vs Sessions[j]..."
        },
        {
          "name": "identify_synchronized_time_slots",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 2,
          "docstring": "Identify time slots with >60% cross-session occurrence..."
        },
        {
          "name": "analyze_temporal_patterns",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 2,
          "docstring": "Analyze the temporal patterns for evidence of systematic timing..."
        },
        {
          "name": "test_synchronization_hypothesis",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 2,
          "docstring": "Test the core hypothesis: IF event@time occurs on Day_N, THEN probability increases on Day_N+1..."
        },
        {
          "name": "create_synchronization_visualization",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 2,
          "docstring": "Create visualization of temporal synchronization patterns..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/investigate_cross_session_synchronization.py",
          "parameters": 0,
          "docstring": "Main cross-session synchronization investigation..."
        },
        {
          "name": "extract_htf_ltf_relationships",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 0,
          "docstring": "Extract HTF context and corresponding LTF event characteristics..."
        },
        {
          "name": "get_dominant_event",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 1,
          "docstring": "Determine the dominant LTF event type..."
        },
        {
          "name": "analyze_htf_ltf_correlations",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 1,
          "docstring": "Analyze correlations between HTF context and LTF event characteristics..."
        },
        {
          "name": "discover_htf_inheritance_rules",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 1,
          "docstring": "Discover rules for how HTF states influence LTF event characteristics..."
        },
        {
          "name": "analyze_event_type_htf_preferences",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 1,
          "docstring": "Analyze HTF context preferences for different LTF event types..."
        },
        {
          "name": "test_htf_coherence_hypothesis",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 1,
          "docstring": "Test the specific hypothesis that discovered patterns align across timeframes..."
        },
        {
          "name": "create_htf_inheritance_visualization",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 4,
          "docstring": "Create comprehensive visualization of HTF-LTF inheritance patterns..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/investigate_htf_structural_inheritance.py",
          "parameters": 0,
          "docstring": "Main HTF structural inheritance investigation..."
        },
        {
          "name": "load_tgat_patterns",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 0,
          "docstring": "Load the 568 TGAT patterns with full feature data..."
        },
        {
          "name": "load_feature_vectors",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 0,
          "docstring": "Load 38D feature vectors from preserved graphs..."
        },
        {
          "name": "analyze_pattern_archetypes",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 1,
          "docstring": "Analyze the distribution and characteristics of the 3 main pattern types..."
        },
        {
          "name": "discover_sub_patterns",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 3,
          "docstring": "Discover sub-patterns using k-means clustering on 38D feature space..."
        },
        {
          "name": "analyze_clusters",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 3,
          "docstring": "Analyze the characteristics of discovered clusters..."
        },
        {
          "name": "calculate_silhouette_score",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 2,
          "docstring": "Calculate silhouette score for cluster quality assessment..."
        },
        {
          "name": "visualize_sub_patterns",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 3,
          "docstring": "Create visualization of discovered sub-patterns..."
        },
        {
          "name": "characterize_sub_patterns",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 3,
          "docstring": "Characterize the discovered sub-patterns with detailed analysis..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/investigate_pattern_subarchitecture.py",
          "parameters": 0,
          "docstring": "Main sub-pattern discovery analysis..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/phase2_feature_pipeline_enhancement.py",
          "parameters": 0,
          "docstring": "Main execution for Phase 2 Feature Pipeline Enhancement...."
        },
        {
          "name": "run_phase4a_full_scale",
          "file": "scripts/analysis/phase4_full_scale_archaeological_discovery.py",
          "parameters": 0,
          "docstring": "Run Phase 4a full scale archaeological discovery...."
        },
        {
          "name": "run_phase4b_attention_analysis",
          "file": "scripts/analysis/phase4b_attention_head_analysis.py",
          "parameters": 0,
          "docstring": "Run Phase 4b attention head analysis...."
        },
        {
          "name": "attention_hook",
          "file": "scripts/analysis/phase4b_attention_head_analysis.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "hook_fn",
          "file": "scripts/analysis/phase4b_attention_head_analysis.py",
          "parameters": 3,
          "docstring": ""
        },
        {
          "name": "run_phase4b_attention_analysis",
          "file": "scripts/analysis/phase4b_attention_verification.py",
          "parameters": 0,
          "docstring": "Run Phase 4b attention head analysis...."
        },
        {
          "name": "run_phase4c_temporal_resonance",
          "file": "scripts/analysis/phase4c_temporal_resonance.py",
          "parameters": 0,
          "docstring": "Run Phase 4c temporal resonance analysis...."
        },
        {
          "name": "extract_date",
          "file": "scripts/analysis/phase4c_temporal_resonance.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "main",
          "file": "scripts/analysis/phase5_archaeological_discovery_validation.py",
          "parameters": 0,
          "docstring": "Execute Phase 5 Archaeological Discovery Validation..."
        },
        {
          "name": "make_serializable",
          "file": "scripts/analysis/phase5_direct_tgat_validation.py",
          "parameters": 1,
          "docstring": "Convert complex objects to JSON-serializable format.\nHandles RichNodeFeature, torch.Tensor, and othe..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/phase5_direct_tgat_validation.py",
          "parameters": 0,
          "docstring": "Execute Phase 5 Direct TGAT Validation..."
        },
        {
          "name": "create_mock_graph_from_session",
          "file": "scripts/analysis/phase5_enhanced_session_validation.py",
          "parameters": 1,
          "docstring": "Convert enhanced session data to graph format for TGAT\nReturns: (X, edge_index, edge_times, edge_att..."
        },
        {
          "name": "test_enhanced_session_pattern_discovery",
          "file": "scripts/analysis/phase5_enhanced_session_validation.py",
          "parameters": 0,
          "docstring": "Test TGAT pattern discovery on enhanced sessions..."
        },
        {
          "name": "analyze_pattern_quality_improvement",
          "file": "scripts/analysis/phase5_enhanced_session_validation.py",
          "parameters": 1,
          "docstring": "Analyze if enhanced sessions show improved pattern quality..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/phase5_enhanced_session_validation.py",
          "parameters": 0,
          "docstring": "Run enhanced session validation..."
        },
        {
          "name": "process_all_sessions",
          "file": "scripts/analysis/process_all_sessions.py",
          "parameters": 0,
          "docstring": "Process all available sessions with time pattern analysis..."
        },
        {
          "name": "analyze_all_time_patterns",
          "file": "scripts/analysis/process_all_sessions.py",
          "parameters": 0,
          "docstring": "Analyze time patterns from all preserved graphs..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/quick_pattern_discovery.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "extract_price_from_node_feature",
          "file": "scripts/analysis/real_pattern_finder.py",
          "parameters": 1,
          "docstring": "Extract price from RichNodeFeature string representation..."
        },
        {
          "name": "find_real_patterns",
          "file": "scripts/analysis/real_pattern_finder.py",
          "parameters": 0,
          "docstring": "Find ONE specific real pattern across all sessions:\n- 1m node near 23,000 level  \n- Has scale edge t..."
        },
        {
          "name": "setup_demonstration_environment",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 0,
          "docstring": "Setup demonstration environment..."
        },
        {
          "name": "generate_synthetic_archaeological_events",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 0,
          "docstring": "Generate comprehensive synthetic archaeological events..."
        },
        {
          "name": "demonstrate_lattice_mapping",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 1,
          "docstring": "Demonstrate lattice mapping capabilities..."
        },
        {
          "name": "demonstrate_temporal_clustering",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 1,
          "docstring": "Demonstrate temporal clustering analysis..."
        },
        {
          "name": "demonstrate_structural_analysis",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 1,
          "docstring": "Demonstrate structural relationship analysis..."
        },
        {
          "name": "create_demonstration_visualizations",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 3,
          "docstring": "Create comprehensive demonstration visualizations..."
        },
        {
          "name": "generate_demonstration_report",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 5,
          "docstring": "Generate comprehensive demonstration report..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 0,
          "docstring": "Main demonstration workflow..."
        },
        {
          "name": "find_cascade_paths",
          "file": "scripts/analysis/run_archaeology_demonstration.py",
          "parameters": 3,
          "docstring": ""
        },
        {
          "name": "get_contaminated_sessions",
          "file": "scripts/analysis/run_contaminated_session_enhancement.py",
          "parameters": 0,
          "docstring": "Get list of contaminated sessions that need enhancement...."
        },
        {
          "name": "main",
          "file": "scripts/analysis/run_contaminated_session_enhancement.py",
          "parameters": 0,
          "docstring": "Run enhancement on contaminated sessions...."
        },
        {
          "name": "run_quick_demo",
          "file": "scripts/analysis/run_enhanced_adapter_demonstration.py",
          "parameters": 0,
          "docstring": "Run a quick demonstration with 3 sessions..."
        },
        {
          "name": "run_full_demo",
          "file": "scripts/analysis/run_enhanced_adapter_demonstration.py",
          "parameters": 0,
          "docstring": "Run full demonstration with more sessions..."
        },
        {
          "name": "run_integration_test",
          "file": "scripts/analysis/run_enhanced_adapter_demonstration.py",
          "parameters": 0,
          "docstring": "Run integration test simulating production environment..."
        },
        {
          "name": "setup_production_environment",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 0,
          "docstring": "Setup production environment for archaeological discovery..."
        },
        {
          "name": "discover_archaeological_phenomena",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 0,
          "docstring": "Run comprehensive archaeological discovery..."
        },
        {
          "name": "generate_lattice_mapping",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 1,
          "docstring": "Generate complete lattice mapping with hot zones..."
        },
        {
          "name": "analyze_temporal_patterns",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 1,
          "docstring": "Analyze temporal clustering patterns..."
        },
        {
          "name": "analyze_structural_relationships",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 1,
          "docstring": "Analyze structural links and cascade patterns..."
        },
        {
          "name": "create_comprehensive_visualizations",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 3,
          "docstring": "Create comprehensive visualization suite..."
        },
        {
          "name": "generate_executive_report",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 1,
          "docstring": "Generate executive summary report..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/run_full_archaeology_discovery.py",
          "parameters": 0,
          "docstring": "Main production archaeological discovery workflow..."
        },
        {
          "name": "run_full_scale_discovery",
          "file": "scripts/analysis/run_full_scale_discovery.py",
          "parameters": 0,
          "docstring": "Execute full-scale archaeological discovery on all 66 sessions..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/run_htf_orchestrator.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "main",
          "file": "scripts/utilities/lattice_population_runner.py",
          "parameters": 0,
          "docstring": "Run the complete lattice population..."
        }
      ],
      "avg_complexity": 31.84
    },
    "learning": {
      "description": "Machine learning, TGAT discovery, and graph building",
      "components": [
        {
          "name": "archaeological_discovery_clean",
          "file": "archaeological_discovery_clean.py",
          "primary_classes": [
            "ArchaeologicalZone",
            "ArchaeologicalDiscoverer"
          ],
          "primary_functions": [
            "test_archaeological_discovery"
          ],
          "patterns": [],
          "lines_of_code": 375,
          "complexity": 44,
          "class_count": 2,
          "function_count": 8,
          "docstring": "Archaeological Discovery Test with HTF Context\n==============================================\n\nTests TGAT archaeological discovery using HTF-enhanced 51D node features\nto demonstrate the enhanced disc...",
          "imports": 11,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "htf_regime_analysis",
          "file": "htf_regime_analysis.py",
          "primary_classes": [
            "RegimeCharacteristics",
            "HTFRegimeAnalyzer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 352,
          "complexity": 31,
          "class_count": 2,
          "function_count": 11,
          "docstring": "HTF Regime Analysis for Archaeological Discovery\n==============================================\n\nAnalyzes HTF context features across different market regimes to understand\ntheir archaeological discov...",
          "imports": 15,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "taxonomy_v1",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "primary_classes": [
            "EventType",
            "EdgeType",
            "Direction",
            "Location",
            "MarketEvent",
            "EventRelationship",
            "TaxonomyMetadata"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 119,
          "complexity": 6,
          "class_count": 7,
          "function_count": 4,
          "docstring": "Event Taxonomy v1.0 Contracts\n=============================\n\nCanonical dataclasses for IRONFORGE event taxonomy standardization.\nSupports the original taxonomy: Expansion, Consolidation, Retracement, ...",
          "imports": 4,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "json_to_parquet",
          "file": "ironforge/converters/json_to_parquet.py",
          "primary_classes": [
            "ConversionConfig",
            "TimeProcessor",
            "FeatureExtractor",
            "NodeIDManager",
            "JSONToParquetConverter"
          ],
          "primary_functions": [
            "convert_enhanced_sessions"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 836,
          "complexity": 142,
          "class_count": 5,
          "function_count": 35,
          "docstring": "Enhanced JSON to Parquet Shard Converter\n========================================\n\nConverts IRONFORGE enhanced session JSON files to Parquet shards suitable for TGAT discovery.\nImplements the specific...",
          "imports": 24,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "__init__",
          "file": "ironforge/graph_builder/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 1,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "igraph_builder",
          "file": "ironforge/graph_builder/igraph_builder.py",
          "primary_classes": [],
          "primary_functions": [
            "from_parquet"
          ],
          "patterns": [],
          "lines_of_code": 15,
          "complexity": 3,
          "class_count": 0,
          "function_count": 1,
          "docstring": "",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "pyg_converters",
          "file": "ironforge/graph_builder/pyg_converters.py",
          "primary_classes": [],
          "primary_functions": [
            "igraph_to_pyg"
          ],
          "patterns": [],
          "lines_of_code": 8,
          "complexity": 1,
          "class_count": 0,
          "function_count": 1,
          "docstring": "",
          "imports": 1,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/learning/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 26,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Learning components for archaeological discovery...",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "discovery_pipeline",
          "file": "ironforge/learning/discovery_pipeline.py",
          "primary_classes": [],
          "primary_functions": [
            "run_discovery"
          ],
          "patterns": [],
          "lines_of_code": 39,
          "complexity": 2,
          "class_count": 0,
          "function_count": 1,
          "docstring": "",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "enhanced_graph_builder",
          "file": "ironforge/learning/enhanced_graph_builder.py",
          "primary_classes": [
            "RichNodeFeature",
            "RichEdgeFeature",
            "EnhancedGraphBuilder"
          ],
          "primary_functions": [
            "get_zone"
          ],
          "patterns": [
            "Factory",
            "Builder"
          ],
          "lines_of_code": 1095,
          "complexity": 199,
          "class_count": 3,
          "function_count": 31,
          "docstring": "Enhanced Graph Builder for 45D/20D architecture\nArchaeological discovery graph construction with semantic features...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "tgat_discovery",
          "file": "ironforge/learning/tgat_discovery.py",
          "primary_classes": [
            "TemporalAttentionLayer",
            "IRONFORGEDiscovery"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 339,
          "complexity": 17,
          "class_count": 2,
          "function_count": 8,
          "docstring": "TGAT Discovery Engine for Archaeological Pattern Discovery\nTemporal Graph Attention Network for market pattern archaeology...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "orchestrator",
          "file": "orchestrator.py",
          "primary_classes": [
            "IRONFORGE"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 586,
          "complexity": 56,
          "class_count": 1,
          "function_count": 14,
          "docstring": "IRONFORGE Main Orchestrator\nCoordinates learning, preservation, and synthesis\nEnhanced with Performance Monitor for Sprint 2 tracking...",
          "imports": 23,
          "decorators": [
            "property"
          ]
        }
      ],
      "file_count": 12,
      "total_lines": 3791,
      "complexity_score": 501,
      "key_classes": [
        {
          "name": "ArchaeologicalZone",
          "file": "archaeological_discovery_clean.py",
          "docstring": "Represents a discovered archaeological zone..."
        },
        {
          "name": "ArchaeologicalDiscoverer",
          "file": "archaeological_discovery_clean.py",
          "docstring": "Enhanced archaeological discovery using HTF context features..."
        },
        {
          "name": "RegimeCharacteristics",
          "file": "htf_regime_analysis.py",
          "docstring": "Characteristics of a market regime..."
        },
        {
          "name": "HTFRegimeAnalyzer",
          "file": "htf_regime_analysis.py",
          "docstring": "Analyzes HTF features across different market regimes..."
        },
        {
          "name": "EventType",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Canonical event types for archaeological discovery..."
        },
        {
          "name": "EdgeType",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Graph edge relationship types..."
        },
        {
          "name": "Direction",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Market direction classification..."
        },
        {
          "name": "Location",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Price location within session context..."
        },
        {
          "name": "MarketEvent",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Canonical market event structure for TGAT discovery pipeline\n\nRequired fields for all events within ..."
        },
        {
          "name": "EventRelationship",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Relationship between two market events for graph edges\n\nMaps directly to Edge.etype for graph repres..."
        },
        {
          "name": "TaxonomyMetadata",
          "file": "ironforge/contracts/taxonomy_v1.py",
          "docstring": "Version and compatibility information..."
        },
        {
          "name": "ConversionConfig",
          "file": "ironforge/converters/json_to_parquet.py",
          "docstring": "Configuration for JSON to Parquet conversion...."
        },
        {
          "name": "TimeProcessor",
          "file": "ironforge/converters/json_to_parquet.py",
          "docstring": "Handles timestamp conversion from session-local to UTC milliseconds...."
        },
        {
          "name": "FeatureExtractor",
          "file": "ironforge/converters/json_to_parquet.py",
          "docstring": "Extracts node features (45D base + optional 6D HTF context) and 20D edge features from session event..."
        },
        {
          "name": "NodeIDManager",
          "file": "ironforge/converters/json_to_parquet.py",
          "docstring": "Manages global unique node IDs across sessions...."
        },
        {
          "name": "JSONToParquetConverter",
          "file": "ironforge/converters/json_to_parquet.py",
          "docstring": "Main converter class for transforming enhanced JSON sessions to Parquet shards...."
        },
        {
          "name": "RichNodeFeature",
          "file": "ironforge/learning/enhanced_graph_builder.py",
          "docstring": "45D node feature vector with semantic preservation..."
        },
        {
          "name": "RichEdgeFeature",
          "file": "ironforge/learning/enhanced_graph_builder.py",
          "docstring": "20D edge feature vector with semantic relationships..."
        },
        {
          "name": "EnhancedGraphBuilder",
          "file": "ironforge/learning/enhanced_graph_builder.py",
          "docstring": "Enhanced graph builder for archaeological discovery\nTransforms JSON session data into rich 45D/20D g..."
        },
        {
          "name": "TemporalAttentionLayer",
          "file": "ironforge/learning/tgat_discovery.py",
          "docstring": "Multi-head temporal attention for 45D node features..."
        },
        {
          "name": "IRONFORGEDiscovery",
          "file": "ironforge/learning/tgat_discovery.py",
          "docstring": "IRONFORGE Discovery Engine using TGAT\nArchaeological pattern discovery through temporal graph attent..."
        },
        {
          "name": "IRONFORGE",
          "file": "orchestrator.py",
          "docstring": "Main orchestrator for discovery system..."
        }
      ],
      "public_interfaces": [
        {
          "name": "test_archaeological_discovery",
          "file": "archaeological_discovery_clean.py",
          "parameters": 0,
          "docstring": "Test archaeological discovery with HTF-enhanced features..."
        },
        {
          "name": "main",
          "file": "htf_regime_analysis.py",
          "parameters": 0,
          "docstring": "Run HTF regime analysis..."
        },
        {
          "name": "convert_enhanced_sessions",
          "file": "ironforge/converters/json_to_parquet.py",
          "parameters": 1,
          "docstring": "Convert all enhanced sessions matching the glob pattern...."
        },
        {
          "name": "from_parquet",
          "file": "ironforge/graph_builder/igraph_builder.py",
          "parameters": 2,
          "docstring": "Build a directed NetworkX graph from node and edge dataframes...."
        },
        {
          "name": "igraph_to_pyg",
          "file": "ironforge/graph_builder/pyg_converters.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "run_discovery",
          "file": "ironforge/learning/discovery_pipeline.py",
          "parameters": 3,
          "docstring": "Run discovery over a list of shard directories.\n\nParameters\n----------\nshard_paths: iterable of str\n..."
        },
        {
          "name": "get_zone",
          "file": "ironforge/learning/enhanced_graph_builder.py",
          "parameters": 1,
          "docstring": ""
        }
      ],
      "avg_complexity": 41.75
    },
    "synthesis": {
      "description": "Pattern validation and production graduation",
      "components": [
        {
          "name": "__init__",
          "file": "ironforge/synthesis/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 15,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Synthesis components for pattern validation...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "pattern_graduation",
          "file": "ironforge/synthesis/pattern_graduation.py",
          "primary_classes": [
            "PatternGraduation"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 213,
          "complexity": 15,
          "class_count": 1,
          "function_count": 6,
          "docstring": "Pattern Graduation System\n87% threshold validation pipeline for discovered patterns...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "production_graduation",
          "file": "ironforge/synthesis/production_graduation.py",
          "primary_classes": [
            "ProductionGraduation"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 268,
          "complexity": 32,
          "class_count": 1,
          "function_count": 8,
          "docstring": "Production Graduation System\nBridge validated patterns to production features...",
          "imports": 9,
          "decorators": []
        }
      ],
      "file_count": 3,
      "total_lines": 496,
      "complexity_score": 47,
      "key_classes": [
        {
          "name": "PatternGraduation",
          "file": "ironforge/synthesis/pattern_graduation.py",
          "docstring": "Validation system ensuring discovered patterns exceed 87% baseline accuracy..."
        },
        {
          "name": "ProductionGraduation",
          "file": "ironforge/synthesis/production_graduation.py",
          "docstring": "Production feature export for graduated patterns\nConverts validated archaeological discoveries into ..."
        }
      ],
      "public_interfaces": [],
      "avg_complexity": 15.67
    },
    "integration": {
      "description": "System integration, configuration, and dependency injection",
      "components": [
        {
          "name": "config",
          "file": "config.py",
          "primary_classes": [
            "IRONFORGEConfig"
          ],
          "primary_functions": [
            "get_config",
            "initialize_config"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 236,
          "complexity": 38,
          "class_count": 1,
          "function_count": 20,
          "docstring": "IRONFORGE Configuration Management\n=================================\n\nCentralized configuration system to eliminate hardcoded paths and make\nIRONFORGE deployable across different environments.\n\nSuppor...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "iron_core/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 39,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Iron-Core: Shared Infrastructure for IRON Ecosystem\n==================================================\n\nProvides common performance, mathematical, and integration components\nfor all IRON suite package...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "iron_core/integration/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 9,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Iron-Core Integration Module\n===========================\n\nCross-suite integration framework for IRON ecosystem.\nFuture home of cross-suite communication protocols....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "iron_core/mathematical/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 21,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Iron-Core Mathematical Module\n============================\n\nShared mathematical components for IRON ecosystem including:\n- Fisher Information Monitor\n- Hawkes Engine \n- Adaptive RG Optimizer\n- Scaling...",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "adaptive_rg_optimizer",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "primary_classes": [
            "AdaptiveRGParameters",
            "ThresholdOptimizationResult",
            "ScalingCalibrationResult",
            "AdaptiveRGOptimizer"
          ],
          "primary_functions": [
            "create_adaptive_rg_optimizer",
            "entropy_objective"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 814,
          "complexity": 78,
          "class_count": 4,
          "function_count": 9,
          "docstring": "Adaptive RG Optimizer - Mathematical Physics Engine\n===================================================\n\nTransforms IRONPULSE from heuristic pattern matching to mathematical physics\nsimulation by impl...",
          "imports": 12,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "cascade_classifier",
          "file": "iron_core/mathematical/cascade_classifier.py",
          "primary_classes": [
            "CascadeType",
            "CascadeEvent",
            "CascadeSequence",
            "CascadeClassifier"
          ],
          "primary_functions": [],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 326,
          "complexity": 33,
          "class_count": 4,
          "function_count": 10,
          "docstring": "Cascade Classification and Sequential Analysis System\nAdvanced system to detect, classify, and correlate cascade types across temporal sequences...",
          "imports": 9,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "constraints",
          "file": "iron_core/mathematical/constraints.py",
          "primary_classes": [
            "SystemConstants",
            "HTFConstants",
            "RGConstants",
            "FPFVGConstants",
            "CascadeType",
            "CASCADE_TYPES_V1",
            "TheoryWeights",
            "ConsensusThresholds",
            "SessionPhases",
            "SessionTypes",
            "BusinessRules",
            "ValidationRules"
          ],
          "primary_functions": [
            "perform_system_integrity_check"
          ],
          "patterns": [],
          "lines_of_code": 411,
          "complexity": 29,
          "class_count": 12,
          "function_count": 17,
          "docstring": "Mathematical Constants and Business Rules - Unified Source of Truth\n\nThis module contains ALL mathematical constants and business rules extracted from the \nproven grok-claude-automation system (91.1% ...",
          "imports": 8,
          "decorators": [
            "classmethod",
            "staticmethod"
          ]
        },
        {
          "name": "fisher_information_monitor",
          "file": "iron_core/mathematical/fisher_information_monitor.py",
          "primary_classes": [
            "FisherSpikeResult",
            "RegimeTransition",
            "FisherInformationMonitor"
          ],
          "primary_functions": [],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 378,
          "complexity": 33,
          "class_count": 3,
          "function_count": 14,
          "docstring": "Fisher Information Spike Monitor - The 24-Minute Crystallization Detector\n=========================================================================\n\nThis module implements the Fisher Information spike...",
          "imports": 10,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "grammar_fisher_correlator",
          "file": "iron_core/mathematical/grammar_fisher_correlator.py",
          "primary_classes": [
            "GrammarParseState",
            "FisherGrammarCorrelation",
            "GrammarFisherCorrelator"
          ],
          "primary_functions": [],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 360,
          "complexity": 43,
          "class_count": 3,
          "function_count": 12,
          "docstring": "Grammar-Fisher Correlation Engine\n=================================\n\nImplements the critical discovery that Fisher spikes correspond to grammatical phrase \nboundaries - moments when partial parse tree...",
          "imports": 9,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "hawkes_engine",
          "file": "iron_core/mathematical/hawkes_engine.py",
          "primary_classes": [
            "HawkesParameters",
            "HawkesEvent",
            "HawkesEngine"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 307,
          "complexity": 25,
          "class_count": 3,
          "function_count": 9,
          "docstring": "Enhanced Multi-Dimensional Hawkes Process Engine\n\nINHERITANCE-BASED ENHANCEMENT APPROACH:\n- Inherits from proven grok-claude-automation HawkesCascadePredictor (91.1% accuracy)\n- Adds multi-dimensional...",
          "imports": 10,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "invariants",
          "file": "iron_core/mathematical/invariants.py",
          "primary_classes": [
            "DriftEvent",
            "Contract",
            "InvariantGuard"
          ],
          "primary_functions": [
            "architectural_control",
            "demo_function",
            "decorator",
            "wrapper"
          ],
          "patterns": [],
          "lines_of_code": 290,
          "complexity": 34,
          "class_count": 3,
          "function_count": 11,
          "docstring": "Invariant Guards - Lightweight Architectural Control System\n==========================================================\n\nFeature drift occurs when implementation entropy exceeds semantic binding energy...",
          "imports": 8,
          "decorators": [
            "dataclass",
            "guard.register"
          ]
        },
        {
          "name": "mathematical_hooks",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "primary_classes": [
            "HookType",
            "AlertLevel",
            "RecoveryAction",
            "HookContext",
            "AlertEvent",
            "MathematicalHook",
            "ParameterDriftHook",
            "PerformanceDegradationHook",
            "MathematicalInvariantValidationHook",
            "HookManager"
          ],
          "primary_functions": [
            "create_oracle_hook_manager"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 831,
          "complexity": 52,
          "class_count": 10,
          "function_count": 17,
          "docstring": "",
          "imports": 16,
          "decorators": [
            "dataclass",
            "abstractmethod"
          ]
        },
        {
          "name": "__init__",
          "file": "iron_core/mathematical/mathematical_layers/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 8,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Mathematical Layers - 5-Layer Architecture Framework\n===================================================\n\nCore mathematical abstractions for the IRON ecosystem....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "api_interface",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "primary_classes": [
            "PredictionRequest",
            "PredictionResponse",
            "ValidationRequest",
            "ValidationResponse",
            "OptimizationRequest",
            "OptimizationResponse",
            "StatusResponse",
            "APIInterfaceLayer",
            "MathematicalModelAPI",
            "BaseModel",
            "FastAPI"
          ],
          "primary_functions": [
            "create_mathematical_api"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 705,
          "complexity": 49,
          "class_count": 11,
          "function_count": 14,
          "docstring": "Layer 5: API Interface Layer\n============================\n\nClean external APIs for mathematical models and integration endpoints.\nProvides REST API, WebSocket, and programmatic interfaces for mathemat...",
          "imports": 27,
          "decorators": [
            "self.app.websocket",
            "self.app.middleware",
            "self.app.get",
            "abstractmethod",
            "self.app.post"
          ]
        },
        {
          "name": "core_algorithms",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "primary_classes": [
            "AlgorithmPerformanceMetrics",
            "CoreAlgorithmLayer",
            "HawkesAlgorithmImplementation",
            "FFTOptimizedCorrelator",
            "QuantumInspiredOptimizer"
          ],
          "primary_functions": [
            "create_algorithm_factory",
            "benchmark_all_algorithms",
            "negative_log_likelihood",
            "quadratic_objective",
            "test_function"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 670,
          "complexity": 63,
          "class_count": 5,
          "function_count": 26,
          "docstring": "Layer 2: Core Algorithms\n========================\n\nHigh-performance implementations of mathematical models with numerical optimization.\nTranslates theoretical models from Layer 1 into efficient, produ...",
          "imports": 18,
          "decorators": [
            "dataclass",
            "abstractmethod"
          ]
        },
        {
          "name": "integration_layer",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "primary_classes": [
            "IntegrationStatus",
            "ModelPriority",
            "ModelMetadata",
            "ModelChainStep",
            "ModelChain",
            "IntegrationLayer",
            "MathematicalModelRegistry"
          ],
          "primary_functions": [
            "create_oracle_prediction_chain",
            "oracle_data_transform",
            "hawkes_output_transform",
            "htf_conditional_execution",
            "htf_parameter_adjustment",
            "consensus_input_transform",
            "consensus_output_transform"
          ],
          "patterns": [
            "Factory",
            "Builder"
          ],
          "lines_of_code": 659,
          "complexity": 77,
          "class_count": 7,
          "function_count": 27,
          "docstring": "Layer 3: Integration Layer\n=========================\n\nConnects mathematical models to business logic and existing Oracle systems.\nProvides model composition, chaining, and seamless integration with Or...",
          "imports": 23,
          "decorators": [
            "dataclass",
            "abstractmethod"
          ]
        },
        {
          "name": "theory_abstraction",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "primary_classes": [
            "MathematicalDomain",
            "MathematicalParameters",
            "MathematicalModel",
            "TheoryAbstractionLayer",
            "HawkesTheoryAbstraction",
            "HTFTheoryAbstraction",
            "InformationTheoreticModel"
          ],
          "primary_functions": [
            "create_mathematical_model_factory",
            "validate_all_mathematical_models"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 434,
          "complexity": 47,
          "class_count": 7,
          "function_count": 37,
          "docstring": "Layer 1: Theory Abstraction\n===========================\n\nPure mathematical formulations without implementation details.\nDefines mathematical models, constraints, and theoretical properties.\n\nThis laye...",
          "imports": 10,
          "decorators": [
            "dataclass",
            "abstractmethod"
          ]
        },
        {
          "name": "rg_scaler_production",
          "file": "iron_core/mathematical/rg_scaler_production.py",
          "primary_classes": [
            "RGScalingResult",
            "RGScaler"
          ],
          "primary_functions": [
            "create_production_rg_scaler"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 356,
          "complexity": 28,
          "class_count": 2,
          "function_count": 9,
          "docstring": "",
          "imports": 7,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "scaling_patterns",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "primary_classes": [
            "ScalingStrategy",
            "ComputationComplexity",
            "ScalingConfig",
            "ScalingMetrics",
            "ScalingPattern",
            "HorizontalScalingPattern",
            "VerticalScalingPattern",
            "AdaptiveScalingManager"
          ],
          "primary_functions": [
            "sample_computation"
          ],
          "patterns": [],
          "lines_of_code": 383,
          "complexity": 33,
          "class_count": 8,
          "function_count": 14,
          "docstring": "Scaling Patterns for Mathematical Computations\n==============================================\n\nHorizontal and vertical scaling patterns with intelligent data partitioning\nfor mathematical model comput...",
          "imports": 17,
          "decorators": [
            "dataclass",
            "abstractmethod"
          ]
        },
        {
          "name": "__init__",
          "file": "iron_core/performance/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 25,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Iron-Core Performance Module\n===========================\n\nLazy loading and dependency injection infrastructure for IRON ecosystem.\nProvides 88.7% performance improvement through component lazy loading...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "container",
          "file": "iron_core/performance/container.py",
          "primary_classes": [
            "IRONContainer"
          ],
          "primary_functions": [
            "get_container",
            "initialize_container"
          ],
          "patterns": [
            "Container/DI"
          ],
          "lines_of_code": 153,
          "complexity": 13,
          "class_count": 1,
          "function_count": 8,
          "docstring": "IRON-Core Container Architecture\n===============================\n\nUnified dependency injection container for the entire IRON ecosystem.\nProvides shared infrastructure for IRONPULSE, IRONFORGE, and fut...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "lazy_loader",
          "file": "iron_core/performance/lazy_loader.py",
          "primary_classes": [
            "LazyComponent",
            "MathematicalComponentLoader",
            "LazyLoadingManager"
          ],
          "primary_functions": [
            "get_lazy_manager",
            "lazy_load",
            "initialize_lazy_loading",
            "decorator",
            "wrapper"
          ],
          "patterns": [],
          "lines_of_code": 349,
          "complexity": 51,
          "class_count": 3,
          "function_count": 21,
          "docstring": "IRONPULSE Lazy Loading Architecture\n==================================\n\nImplements lazy loading for mathematical components to achieve:\n- <5 second system initialization (vs 120+ current)\n- 95% memory...",
          "imports": 9,
          "decorators": [
            "wraps",
            "staticmethod",
            "property"
          ]
        },
        {
          "name": "setup",
          "file": "iron_core/setup.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 126,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Iron-Core Package Setup\n=======================\nShared infrastructure package for IRON ecosystem with dependency injection,\nlazy loading, and mathematical component management.\n\nFeatures:\n- Lazy loadi...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "htf_context_processor",
          "file": "ironforge/converters/htf_context_processor.py",
          "primary_classes": [
            "HTFContextConfig",
            "HTFBar",
            "TimeFrameManager",
            "SyntheticVolumeCalculator",
            "HTFRegimeClassifier",
            "DailyAnchorCalculator",
            "HTFContextProcessor",
            "HTFConstants"
          ],
          "primary_functions": [
            "create_default_htf_config"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 578,
          "complexity": 74,
          "class_count": 8,
          "function_count": 21,
          "docstring": "HTF Context Processor for IRONFORGE Archaeological Discovery\n==========================================================\n\nAdds Higher Timeframe context features to M5 base events while preserving \nfund...",
          "imports": 18,
          "decorators": [
            "classmethod",
            "staticmethod",
            "dataclass"
          ]
        },
        {
          "name": "__init__",
          "file": "ironforge/integration/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 13,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Integration layer for system coordination...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "ironforge_container",
          "file": "ironforge/integration/ironforge_container.py",
          "primary_classes": [
            "IRONFORGEContainer"
          ],
          "primary_functions": [
            "get_ironforge_container",
            "initialize_ironforge_lazy_loading"
          ],
          "patterns": [
            "Container/DI"
          ],
          "lines_of_code": 81,
          "complexity": 10,
          "class_count": 1,
          "function_count": 6,
          "docstring": "IRONFORGE Container for lazy loading and dependency injection...",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "app_config",
          "file": "ironforge/sdk/app_config.py",
          "primary_classes": [
            "DataCfg",
            "OutputsCfg",
            "WeightsCfg",
            "ScoringCfg",
            "MinidashCfg",
            "ReportingCfg",
            "ValidationCfg",
            "Config"
          ],
          "primary_functions": [
            "load_config",
            "materialize_run_dir"
          ],
          "patterns": [],
          "lines_of_code": 154,
          "complexity": 26,
          "class_count": 8,
          "function_count": 6,
          "docstring": "",
          "imports": 9,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "config",
          "file": "ironforge/sdk/config.py",
          "primary_classes": [
            "LoaderCfg",
            "Paths",
            "ConfluenceCfg",
            "RunCfg"
          ],
          "primary_functions": [
            "load_cfg"
          ],
          "patterns": [],
          "lines_of_code": 63,
          "complexity": 4,
          "class_count": 4,
          "function_count": 3,
          "docstring": "",
          "imports": 5,
          "decorators": [
            "dataclass"
          ]
        }
      ],
      "file_count": 28,
      "total_lines": 8779,
      "complexity_score": 840,
      "key_classes": [
        {
          "name": "IRONFORGEConfig",
          "file": "config.py",
          "docstring": "Configuration manager for IRONFORGE system.\n\nEliminates hardcoded paths and provides environment-spe..."
        },
        {
          "name": "AdaptiveRGParameters",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "docstring": "Optimized RG parameters for current market regime..."
        },
        {
          "name": "ThresholdOptimizationResult",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "docstring": "Result from information-theoretic threshold optimization..."
        },
        {
          "name": "ScalingCalibrationResult",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "docstring": "Result from RG scaling exponent calibration..."
        },
        {
          "name": "AdaptiveRGOptimizer",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "docstring": "Mathematical Physics Engine for RG Optimization\n\nImplements the complete transformation from heurist..."
        },
        {
          "name": "CascadeType",
          "file": "iron_core/mathematical/cascade_classifier.py",
          "docstring": ""
        },
        {
          "name": "CascadeEvent",
          "file": "iron_core/mathematical/cascade_classifier.py",
          "docstring": "Individual cascade event with full context..."
        },
        {
          "name": "CascadeSequence",
          "file": "iron_core/mathematical/cascade_classifier.py",
          "docstring": "Sequence of related cascade events..."
        },
        {
          "name": "CascadeClassifier",
          "file": "iron_core/mathematical/cascade_classifier.py",
          "docstring": "Advanced cascade classification system with sequential analysis\n\nClassifies individual cascade event..."
        },
        {
          "name": "SystemConstants",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Core mathematical invariants - DO NOT MODIFY..."
        },
        {
          "name": "HTFConstants",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Higher Timeframe (HTF) System Parameters - IMMUTABLE..."
        },
        {
          "name": "RGConstants",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Renormalization Group (RG) Scaling Constants - IMMUTABLE..."
        },
        {
          "name": "FPFVGConstants",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Fair Price Fair Value Gap (FPFVG) Constants - 87.5% Contamination Filtering..."
        },
        {
          "name": "CascadeType",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "CASCADE_TYPES v1.0 - IMMUTABLE Taxonomy..."
        },
        {
          "name": "CASCADE_TYPES_V1",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Immutable cascade classification system - DO NOT MODIFY..."
        },
        {
          "name": "TheoryWeights",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Multi-Theory Integration Weights - IMMUTABLE..."
        },
        {
          "name": "ConsensusThresholds",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Multi-Theory Consensus Decision Thresholds..."
        },
        {
          "name": "SessionPhases",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Session Phase Enumeration..."
        },
        {
          "name": "SessionTypes",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Trading Session Types..."
        },
        {
          "name": "BusinessRules",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Domain-Specific Business Logic - Critical for System Accuracy..."
        },
        {
          "name": "ValidationRules",
          "file": "iron_core/mathematical/constraints.py",
          "docstring": "Validation rules for mathematical integrity..."
        },
        {
          "name": "FisherSpikeResult",
          "file": "iron_core/mathematical/fisher_information_monitor.py",
          "docstring": "Result from Fisher Information spike analysis..."
        },
        {
          "name": "RegimeTransition",
          "file": "iron_core/mathematical/fisher_information_monitor.py",
          "docstring": "Detected regime transition event..."
        },
        {
          "name": "FisherInformationMonitor",
          "file": "iron_core/mathematical/fisher_information_monitor.py",
          "docstring": "Fisher Information Spike Detection System\n\nMonitors Fisher Information to detect the critical crysta..."
        },
        {
          "name": "GrammarParseState",
          "file": "iron_core/mathematical/grammar_fisher_correlator.py",
          "docstring": "Current state of grammatical parsing with Fisher correlation..."
        },
        {
          "name": "FisherGrammarCorrelation",
          "file": "iron_core/mathematical/grammar_fisher_correlator.py",
          "docstring": "Correlation between Fisher spike and grammar phrase boundary..."
        },
        {
          "name": "GrammarFisherCorrelator",
          "file": "iron_core/mathematical/grammar_fisher_correlator.py",
          "docstring": "Predictive parser that tracks Fisher Information as parsing confidence\n\nKey Discovery: Fisher spikes..."
        },
        {
          "name": "HawkesParameters",
          "file": "iron_core/mathematical/hawkes_engine.py",
          "docstring": "Parameters for Hawkes process..."
        },
        {
          "name": "HawkesEvent",
          "file": "iron_core/mathematical/hawkes_engine.py",
          "docstring": "Individual event in Hawkes process..."
        },
        {
          "name": "HawkesEngine",
          "file": "iron_core/mathematical/hawkes_engine.py",
          "docstring": "Enhanced Multi-Dimensional Hawkes Process Engine\n\nImplements proven HTF coupling with multi-dimensio..."
        },
        {
          "name": "DriftEvent",
          "file": "iron_core/mathematical/invariants.py",
          "docstring": "Record of architectural drift detection..."
        },
        {
          "name": "Contract",
          "file": "iron_core/mathematical/invariants.py",
          "docstring": "Semantic binding contract for functions..."
        },
        {
          "name": "InvariantGuard",
          "file": "iron_core/mathematical/invariants.py",
          "docstring": "Minimal viable architectural control system..."
        },
        {
          "name": "HookType",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Types of mathematical model hooks..."
        },
        {
          "name": "AlertLevel",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Alert severity levels..."
        },
        {
          "name": "RecoveryAction",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Automated recovery actions..."
        },
        {
          "name": "HookContext",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Context information for hook execution..."
        },
        {
          "name": "AlertEvent",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Mathematical model alert event..."
        },
        {
          "name": "MathematicalHook",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Base class for mathematical model hooks..."
        },
        {
          "name": "ParameterDriftHook",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Detects parameter drift in mathematical models.\nUses statistical tests and trend analysis to identif..."
        },
        {
          "name": "PerformanceDegradationHook",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Monitors mathematical model performance degradation.\nTracks execution time, memory usage, and accura..."
        },
        {
          "name": "MathematicalInvariantValidationHook",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Validates mathematical invariants and constraints.\nEnsures mathematical models maintain their theore..."
        },
        {
          "name": "HookManager",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "docstring": "Central manager for mathematical model hooks.\nCoordinates hook execution, manages alerts, and handle..."
        },
        {
          "name": "PredictionRequest",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Request schema for mathematical predictions..."
        },
        {
          "name": "PredictionResponse",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Response schema for mathematical predictions..."
        },
        {
          "name": "ValidationRequest",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Request schema for model validation..."
        },
        {
          "name": "ValidationResponse",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Response schema for model validation..."
        },
        {
          "name": "OptimizationRequest",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Request schema for parameter optimization..."
        },
        {
          "name": "OptimizationResponse",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Response schema for parameter optimization..."
        },
        {
          "name": "StatusResponse",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Response schema for system status..."
        },
        {
          "name": "APIInterfaceLayer",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "Base class for API interface implementations.\nProvides framework for exposing mathematical models vi..."
        },
        {
          "name": "MathematicalModelAPI",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": "FastAPI-based REST API for mathematical models.\nProvides comprehensive API endpoints for all mathema..."
        },
        {
          "name": "BaseModel",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": ""
        },
        {
          "name": "FastAPI",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "docstring": ""
        },
        {
          "name": "AlgorithmPerformanceMetrics",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "docstring": "Performance metrics for algorithm implementations..."
        },
        {
          "name": "CoreAlgorithmLayer",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "docstring": "Base class for high-performance algorithm implementations.\nFocuses on computational efficiency and n..."
        },
        {
          "name": "HawkesAlgorithmImplementation",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "docstring": "High-performance Hawkes process implementation with numerical optimizations.\nBased on Oracle system ..."
        },
        {
          "name": "FFTOptimizedCorrelator",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "docstring": "FFT-based correlation optimization reducing O(n¬≤) to O(n log n).\nOptimizes cross-session temporal co..."
        },
        {
          "name": "QuantumInspiredOptimizer",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "docstring": "Quantum-inspired optimization for complex parameter spaces.\nUses simulated annealing with quantum tu..."
        },
        {
          "name": "IntegrationStatus",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Status of model integration..."
        },
        {
          "name": "ModelPriority",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Priority levels for model execution..."
        },
        {
          "name": "ModelMetadata",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Metadata for registered mathematical models..."
        },
        {
          "name": "ModelChainStep",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Individual step in a model execution chain..."
        },
        {
          "name": "ModelChain",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Chain of mathematical models for complex predictions.\nSupports conditional execution, data transform..."
        },
        {
          "name": "IntegrationLayer",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Base class for mathematical model integration with business systems.\nProvides framework for model re..."
        },
        {
          "name": "MathematicalModelRegistry",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "docstring": "Registry for mathematical models with Oracle system integration.\nManages model lifecycle, dependenci..."
        },
        {
          "name": "MathematicalDomain",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Mathematical domains for model classification..."
        },
        {
          "name": "MathematicalParameters",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Type-safe mathematical parameter container with constraints..."
        },
        {
          "name": "MathematicalModel",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Protocol/Interface for mathematical models.\nDefines the contract that all mathematical models must s..."
        },
        {
          "name": "TheoryAbstractionLayer",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Base class for theoretical mathematical model abstractions.\nFocuses purely on mathematical theory wi..."
        },
        {
          "name": "HawkesTheoryAbstraction",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Theoretical abstraction of Hawkes processes.\nBased on the validated Oracle system formulation:\nŒª(t) ..."
        },
        {
          "name": "HTFTheoryAbstraction",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Higher Time Frame (HTF) theoretical abstraction.\nMulti-scale coupling between HTF and session-level ..."
        },
        {
          "name": "InformationTheoreticModel",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "docstring": "Information-theoretic mathematical model for Three-Oracle consensus.\nBased on mutual information max..."
        },
        {
          "name": "RGScalingResult",
          "file": "iron_core/mathematical/rg_scaler_production.py",
          "docstring": "Results from RG scaling transformation..."
        },
        {
          "name": "RGScaler",
          "file": "iron_core/mathematical/rg_scaler_production.py",
          "docstring": "Production RG Scaler - The Universal Lens\n\nImplements the experimentally-discovered inverse scaling ..."
        },
        {
          "name": "ScalingStrategy",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Available scaling strategies..."
        },
        {
          "name": "ComputationComplexity",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Computation complexity levels..."
        },
        {
          "name": "ScalingConfig",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Configuration for scaling operations..."
        },
        {
          "name": "ScalingMetrics",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Metrics from scaling operations..."
        },
        {
          "name": "ScalingPattern",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Abstract base class for scaling patterns..."
        },
        {
          "name": "HorizontalScalingPattern",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Horizontal scaling with data partitioning..."
        },
        {
          "name": "VerticalScalingPattern",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Vertical scaling with memory optimization..."
        },
        {
          "name": "AdaptiveScalingManager",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "docstring": "Manager for adaptive scaling strategy selection..."
        },
        {
          "name": "IRONContainer",
          "file": "iron_core/performance/container.py",
          "docstring": "IRON-Core dependency injection container.\n\nProvides unified infrastructure for mathematical componen..."
        },
        {
          "name": "LazyComponent",
          "file": "iron_core/performance/lazy_loader.py",
          "docstring": "Lazy loading wrapper for mathematical components.\n\nDelays initialization until first access to elimi..."
        },
        {
          "name": "MathematicalComponentLoader",
          "file": "iron_core/performance/lazy_loader.py",
          "docstring": "Specialized loader for IRON ecosystem mathematical components.\n\nProvides validation functions for ma..."
        },
        {
          "name": "LazyLoadingManager",
          "file": "iron_core/performance/lazy_loader.py",
          "docstring": "Manager for lazy loading of IRON ecosystem mathematical components.\n\nImplements performance optimiza..."
        },
        {
          "name": "HTFContextConfig",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Configuration for HTF context processing..."
        },
        {
          "name": "HTFBar",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Represents a closed HTF bar with computed metrics..."
        },
        {
          "name": "TimeFrameManager",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Manages HTF timeframe calculations with leakage prevention..."
        },
        {
          "name": "SyntheticVolumeCalculator",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Calculates Synthetic Volume following mathematical foundations\nPreserves the SV calculation framewor..."
        },
        {
          "name": "HTFRegimeClassifier",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Classifies HTF regime using SV and volatility percentiles..."
        },
        {
          "name": "DailyAnchorCalculator",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Calculates distance to daily anchors for archaeological context..."
        },
        {
          "name": "HTFContextProcessor",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": "Main HTF context processor that adds 6 contextual features to M5 base events\n\nFeatures added: f45_sv..."
        },
        {
          "name": "HTFConstants",
          "file": "ironforge/converters/htf_context_processor.py",
          "docstring": ""
        },
        {
          "name": "IRONFORGEContainer",
          "file": "ironforge/integration/ironforge_container.py",
          "docstring": "Container for lazy loading IRONFORGE components\n\nNOTE: Components are created fresh for each session..."
        },
        {
          "name": "DataCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "OutputsCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "WeightsCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "ScoringCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "MinidashCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "ReportingCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "ValidationCfg",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "Config",
          "file": "ironforge/sdk/app_config.py",
          "docstring": ""
        },
        {
          "name": "LoaderCfg",
          "file": "ironforge/sdk/config.py",
          "docstring": ""
        },
        {
          "name": "Paths",
          "file": "ironforge/sdk/config.py",
          "docstring": ""
        },
        {
          "name": "ConfluenceCfg",
          "file": "ironforge/sdk/config.py",
          "docstring": ""
        },
        {
          "name": "RunCfg",
          "file": "ironforge/sdk/config.py",
          "docstring": ""
        }
      ],
      "public_interfaces": [
        {
          "name": "get_config",
          "file": "config.py",
          "parameters": 1,
          "docstring": "Get or create global IRONFORGE configuration...."
        },
        {
          "name": "initialize_config",
          "file": "config.py",
          "parameters": 1,
          "docstring": "Initialize IRONFORGE configuration system...."
        },
        {
          "name": "create_adaptive_rg_optimizer",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "parameters": 1,
          "docstring": "Factory function for production adaptive RG optimizer..."
        },
        {
          "name": "entropy_objective",
          "file": "iron_core/mathematical/adaptive_rg_optimizer.py",
          "parameters": 1,
          "docstring": "Objective function for maximum entropy threshold optimization..."
        },
        {
          "name": "perform_system_integrity_check",
          "file": "iron_core/mathematical/constraints.py",
          "parameters": 0,
          "docstring": "Perform complete system integrity check on all constants\nReturns dict of validation results..."
        },
        {
          "name": "architectural_control",
          "file": "iron_core/mathematical/invariants.py",
          "parameters": 4,
          "docstring": "Convenience wrapper for guard.register..."
        },
        {
          "name": "demo_function",
          "file": "iron_core/mathematical/invariants.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "decorator",
          "file": "iron_core/mathematical/invariants.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "wrapper",
          "file": "iron_core/mathematical/invariants.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "create_oracle_hook_manager",
          "file": "iron_core/mathematical/mathematical_hooks.py",
          "parameters": 0,
          "docstring": "Create HookManager with Oracle-specific configuration..."
        },
        {
          "name": "create_mathematical_api",
          "file": "iron_core/mathematical/mathematical_layers/api_interface.py",
          "parameters": 2,
          "docstring": "Create mathematical model API with registry and hooks..."
        },
        {
          "name": "create_algorithm_factory",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "parameters": 0,
          "docstring": "Factory for creating algorithm implementations..."
        },
        {
          "name": "benchmark_all_algorithms",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "parameters": 0,
          "docstring": "Benchmark all algorithm implementations..."
        },
        {
          "name": "negative_log_likelihood",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "parameters": 1,
          "docstring": "Negative log-likelihood objective function..."
        },
        {
          "name": "quadratic_objective",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "test_function",
          "file": "iron_core/mathematical/mathematical_layers/core_algorithms.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "create_oracle_prediction_chain",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 0,
          "docstring": "Create standard Oracle prediction chain..."
        },
        {
          "name": "oracle_data_transform",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 1,
          "docstring": "Transform Oracle session data for Hawkes input..."
        },
        {
          "name": "hawkes_output_transform",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 1,
          "docstring": "Transform Hawkes output for Oracle consumption..."
        },
        {
          "name": "htf_conditional_execution",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 1,
          "docstring": "Execute HTF coupling only if intensity exceeds threshold..."
        },
        {
          "name": "htf_parameter_adjustment",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 1,
          "docstring": "Adjust HTF parameters based on previous predictions..."
        },
        {
          "name": "consensus_input_transform",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 1,
          "docstring": "Prepare data for Three-Oracle system..."
        },
        {
          "name": "consensus_output_transform",
          "file": "iron_core/mathematical/mathematical_layers/integration_layer.py",
          "parameters": 1,
          "docstring": "Transform consensus output for final prediction..."
        },
        {
          "name": "create_mathematical_model_factory",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "parameters": 0,
          "docstring": "Factory for creating mathematical model instances..."
        },
        {
          "name": "validate_all_mathematical_models",
          "file": "iron_core/mathematical/mathematical_layers/theory_abstraction.py",
          "parameters": 0,
          "docstring": "Validate consistency of all mathematical models..."
        },
        {
          "name": "create_production_rg_scaler",
          "file": "iron_core/mathematical/rg_scaler_production.py",
          "parameters": 1,
          "docstring": "Create production-ready RG Scaler instance\n\nArgs:\n    config: Optional configuration overrides\n    \n..."
        },
        {
          "name": "sample_computation",
          "file": "iron_core/mathematical/scaling_patterns.py",
          "parameters": 1,
          "docstring": "Sample mathematical computation..."
        },
        {
          "name": "get_container",
          "file": "iron_core/performance/container.py",
          "parameters": 0,
          "docstring": "Get global IRON-Core dependency injection container with thread-safe singleton pattern.\n\nThis implem..."
        },
        {
          "name": "initialize_container",
          "file": "iron_core/performance/container.py",
          "parameters": 0,
          "docstring": "Initialize IRON-Core container with performance reporting...."
        },
        {
          "name": "get_lazy_manager",
          "file": "iron_core/performance/lazy_loader.py",
          "parameters": 0,
          "docstring": "Get global lazy loading manager with thread-safe singleton pattern.\n\nThread Safety:\n    This functio..."
        },
        {
          "name": "lazy_load",
          "file": "iron_core/performance/lazy_loader.py",
          "parameters": 4,
          "docstring": "Decorator for lazy loading components (thread-safe)...."
        },
        {
          "name": "initialize_lazy_loading",
          "file": "iron_core/performance/lazy_loader.py",
          "parameters": 0,
          "docstring": "Initialize lazy loading with standard IRON ecosystem components (thread-safe)...."
        },
        {
          "name": "decorator",
          "file": "iron_core/performance/lazy_loader.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "wrapper",
          "file": "iron_core/performance/lazy_loader.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "create_default_htf_config",
          "file": "ironforge/converters/htf_context_processor.py",
          "parameters": 0,
          "docstring": "Create default HTF context configuration..."
        },
        {
          "name": "get_ironforge_container",
          "file": "ironforge/integration/ironforge_container.py",
          "parameters": 0,
          "docstring": "Get the global IRONFORGE container instance..."
        },
        {
          "name": "initialize_ironforge_lazy_loading",
          "file": "ironforge/integration/ironforge_container.py",
          "parameters": 0,
          "docstring": "Initialize IRONFORGE lazy loading system..."
        },
        {
          "name": "load_config",
          "file": "ironforge/sdk/app_config.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "materialize_run_dir",
          "file": "ironforge/sdk/app_config.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "load_cfg",
          "file": "ironforge/sdk/config.py",
          "parameters": 1,
          "docstring": "Load a run configuration from YAML...."
        }
      ],
      "avg_complexity": 30.0
    },
    "validation": {
      "description": "Testing, validation, and quality assurance",
      "components": [
        {
          "name": "validation_framework",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "primary_classes": [
            "ValidationLevel",
            "TestResult",
            "ValidationResult",
            "ValidationSuite",
            "ValidationLayer",
            "MathematicalPropertyTest",
            "NumericalStabilityTest",
            "PerformanceBenchmarkTest",
            "MathematicalValidationFramework",
            "MockHawkesModel",
            "st"
          ],
          "primary_functions": [
            "create_validation_framework",
            "given",
            "decorator"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 1403,
          "complexity": 153,
          "class_count": 11,
          "function_count": 35,
          "docstring": "Layer 4: Validation Framework\n============================\n\nComprehensive mathematical testing framework with property-based validation.\nEnsures mathematical accuracy, numerical stability, and perform...",
          "imports": 19,
          "decorators": [
            "staticmethod",
            "dataclass",
            "abstractmethod"
          ]
        },
        {
          "name": "__init__",
          "file": "iron_core/validation/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 8,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Iron-Core Validation Module\n===========================\n\nSystem health validation and testing framework for IRON ecosystem....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/validation/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 1,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "oos",
          "file": "ironforge/validation/oos.py",
          "primary_classes": [],
          "primary_functions": [
            "run_oos"
          ],
          "patterns": [],
          "lines_of_code": 16,
          "complexity": 1,
          "class_count": 0,
          "function_count": 1,
          "docstring": "",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/validation_engine/__init__.py",
          "primary_classes": [],
          "primary_functions": [
            "validate_run"
          ],
          "patterns": [],
          "lines_of_code": 25,
          "complexity": 1,
          "class_count": 0,
          "function_count": 1,
          "docstring": "IRONFORGE Validation Engine\n===========================\n\nArchaeological discovery validation and quality assurance.\nThin re-export layer for canonical import paths....",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "run_weekly_daily_sweep_cascade_step_3b",
          "file": "run_weekly_daily_sweep_cascade_step_3b.py",
          "primary_classes": [],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 240,
          "complexity": 20,
          "class_count": 0,
          "function_count": 1,
          "docstring": "üìà IRONFORGE Weekly‚ÜíDaily Liquidity Sweep Cascade Analysis (Step 3B) - Execution\n================================================================================\n\nMacro Driver Analysis: Weekly dominanc...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "validate_ci_setup",
          "file": "validate_ci_setup.py",
          "primary_classes": [],
          "primary_functions": [
            "run_command",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 82,
          "complexity": 11,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Local CI Validation Script\n==========================\nTest the same commands that CI will run to ensure local/CI parity....",
          "imports": 3,
          "decorators": []
        }
      ],
      "file_count": 7,
      "total_lines": 1775,
      "complexity_score": 186,
      "key_classes": [
        {
          "name": "ValidationLevel",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Validation thoroughness levels..."
        },
        {
          "name": "TestResult",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Test result status..."
        },
        {
          "name": "ValidationResult",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Result of a validation test..."
        },
        {
          "name": "ValidationSuite",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Collection of validation results..."
        },
        {
          "name": "ValidationLayer",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Base class for validation layer implementations.\nProvides framework for mathematical accuracy and pe..."
        },
        {
          "name": "MathematicalPropertyTest",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Property-based testing for mathematical models.\nTests mathematical properties using generated data...."
        },
        {
          "name": "NumericalStabilityTest",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Tests for numerical stability of mathematical implementations.\nChecks behavior under extreme conditi..."
        },
        {
          "name": "PerformanceBenchmarkTest",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Performance benchmarking for mathematical implementations.\nTests execution time, memory usage, and s..."
        },
        {
          "name": "MathematicalValidationFramework",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": "Comprehensive validation framework that combines all testing approaches.\nMain entry point for mathem..."
        },
        {
          "name": "MockHawkesModel",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": ""
        },
        {
          "name": "st",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "docstring": ""
        }
      ],
      "public_interfaces": [
        {
          "name": "create_validation_framework",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "parameters": 1,
          "docstring": "Create mathematical validation framework with specified level..."
        },
        {
          "name": "given",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "decorator",
          "file": "iron_core/mathematical/mathematical_layers/validation_framework.py",
          "parameters": 1,
          "docstring": ""
        },
        {
          "name": "run_oos",
          "file": "ironforge/validation/oos.py",
          "parameters": 1,
          "docstring": "Stub out-of-sample validation that writes a report...."
        },
        {
          "name": "validate_run",
          "file": "ironforge/validation_engine/__init__.py",
          "parameters": 2,
          "docstring": "Stub function when validation runner is not available..."
        },
        {
          "name": "main",
          "file": "run_weekly_daily_sweep_cascade_step_3b.py",
          "parameters": 0,
          "docstring": "Execute Weekly‚ÜíDaily Liquidity Sweep Cascade Analysis (Step 3B)..."
        },
        {
          "name": "run_command",
          "file": "validate_ci_setup.py",
          "parameters": 2,
          "docstring": "Run a command and return True if successful...."
        },
        {
          "name": "main",
          "file": "validate_ci_setup.py",
          "parameters": 0,
          "docstring": ""
        }
      ],
      "avg_complexity": 26.57
    },
    "reporting": {
      "description": "Report generation and data visualization",
      "components": [
        {
          "name": "htf_observer",
          "file": "ironforge/reporting/htf_observer.py",
          "primary_classes": [
            "HTFRunSummary",
            "HTFObserver"
          ],
          "primary_functions": [
            "test_htf_observer"
          ],
          "patterns": [],
          "lines_of_code": 374,
          "complexity": 38,
          "class_count": 2,
          "function_count": 12,
          "docstring": "HTF Context Observability\n========================\n\nLight observability for HTF context features with run-level summaries\nand regime monitoring for archaeological discovery insights....",
          "imports": 12,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "minidash",
          "file": "ironforge/reporting/minidash.py",
          "primary_classes": [],
          "primary_functions": [
            "build_minidash"
          ],
          "patterns": [],
          "lines_of_code": 99,
          "complexity": 5,
          "class_count": 0,
          "function_count": 1,
          "docstring": "",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "writers",
          "file": "ironforge/reporting/writers.py",
          "primary_classes": [],
          "primary_functions": [
            "save_json",
            "save_html",
            "save_png"
          ],
          "patterns": [],
          "lines_of_code": 28,
          "complexity": 4,
          "class_count": 0,
          "function_count": 4,
          "docstring": "",
          "imports": 4,
          "decorators": []
        }
      ],
      "file_count": 3,
      "total_lines": 501,
      "complexity_score": 47,
      "key_classes": [
        {
          "name": "HTFRunSummary",
          "file": "ironforge/reporting/htf_observer.py",
          "docstring": "Summary statistics for HTF features across a discovery run..."
        },
        {
          "name": "HTFObserver",
          "file": "ironforge/reporting/htf_observer.py",
          "docstring": "Light observability for HTF context features..."
        }
      ],
      "public_interfaces": [
        {
          "name": "test_htf_observer",
          "file": "ironforge/reporting/htf_observer.py",
          "parameters": 0,
          "docstring": "Test HTF observer with sample data..."
        },
        {
          "name": "build_minidash",
          "file": "ironforge/reporting/minidash.py",
          "parameters": 8,
          "docstring": ""
        },
        {
          "name": "save_json",
          "file": "ironforge/reporting/writers.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "save_html",
          "file": "ironforge/reporting/writers.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "save_png",
          "file": "ironforge/reporting/writers.py",
          "parameters": 2,
          "docstring": "Save a Matplotlib figure as PNG...."
        }
      ],
      "avg_complexity": 15.67
    },
    "utilities": {
      "description": "Utility functions, scripts, and support tools",
      "components": [
        {
          "name": "batch_migrate_graphs",
          "file": "data_migration/batch_migrate_graphs.py",
          "primary_classes": [
            "BatchGraphMigrator"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 550,
          "complexity": 58,
          "class_count": 1,
          "function_count": 8,
          "docstring": "IRONFORGE Batch Graph Schema Migration\n======================================\n\nTechnical Debt Surgeon: Batch processing script for migrating\nlegacy 34D graph files to current 37D schema format while\nm...",
          "imports": 11,
          "decorators": []
        },
        {
          "name": "schema_normalizer",
          "file": "data_migration/schema_normalizer.py",
          "primary_classes": [
            "SchemaNormalizer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 386,
          "complexity": 47,
          "class_count": 1,
          "function_count": 10,
          "docstring": "IRONFORGE Schema Normalization - Technical Debt Surgeon Implementation\n====================================================================\n\nMigrates legacy 34D data to current 37D schema while mainta...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/utilities/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 12,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Core utilities and helpers...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "performance_monitor",
          "file": "ironforge/utilities/performance_monitor.py",
          "primary_classes": [
            "PerformanceMonitor"
          ],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 69,
          "complexity": 6,
          "class_count": 1,
          "function_count": 3,
          "docstring": "Performance Monitor\nUtility for monitoring IRONFORGE component performance...",
          "imports": 4,
          "decorators": [
            "contextmanager"
          ]
        },
        {
          "name": "__init__",
          "file": "scripts/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 9,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Scripts Package\n========================\nUtility scripts for analysis, data processing, and system utilities....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "scripts/analysis/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 8,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Analysis Scripts\n=========================\nScripts for running analysis workflows and archaeological discovery....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "complete_phase2_enhancement",
          "file": "scripts/analysis/complete_phase2_enhancement.py",
          "primary_classes": [],
          "primary_functions": [
            "generate_authentic_htf_carryover",
            "generate_authentic_energy_density",
            "generate_liquidity_events",
            "enhance_session_features",
            "process_remaining_sessions"
          ],
          "patterns": [],
          "lines_of_code": 280,
          "complexity": 23,
          "class_count": 0,
          "function_count": 5,
          "docstring": "Complete Phase 2 Feature Decontamination\n=======================================\nProcesses all remaining TGAT-ready sessions to achieve 100% coverage.\n\nEnhances the remaining 24 sessions with authenti...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "investigate_causal_event_chains",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "primary_classes": [],
          "primary_functions": [
            "extract_event_sequences",
            "build_transition_matrices",
            "analyze_lag_profiles",
            "identify_causal_chains",
            "test_specific_hypothesis",
            "create_causal_chain_visualization",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 591,
          "complexity": 82,
          "class_count": 0,
          "function_count": 7,
          "docstring": "RANK 2: Multi-Event Causal Chain Investigation\n===============================================\nDiscover predictable sequences: expansion_phase ‚Üí consolidation ‚Üí liq_sweep\nwith consistent lag profiles ...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "investigate_liquidity_sweep_catalyst",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "primary_classes": [],
          "primary_functions": [
            "extract_liquidity_sweep_sequences",
            "analyze_immediate_responses",
            "discover_catalyst_chains",
            "analyze_catalyst_timing_patterns",
            "test_specific_catalyst_hypotheses",
            "create_catalyst_visualization",
            "main"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 671,
          "complexity": 79,
          "class_count": 0,
          "function_count": 7,
          "docstring": "Liquidity Sweep Catalyst Investigation\n======================================\nInvestigating liq_sweep as initiating event rather than terminal event.\nFocus on discovering what causal chains liq_sweep ...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "phase2_validation_framework",
          "file": "scripts/analysis/phase2_validation_framework.py",
          "primary_classes": [
            "FeatureAuthenticityValidator"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 412,
          "complexity": 55,
          "class_count": 1,
          "function_count": 12,
          "docstring": "IRONFORGE Phase 2: Feature Authenticity Validation Framework\n=========================================================\n\nValidates that decontamination successfully removed artificial default values\nan...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "phase2_validation_summary",
          "file": "scripts/analysis/phase2_validation_summary.py",
          "primary_classes": [],
          "primary_functions": [
            "validate_decontamination"
          ],
          "patterns": [],
          "lines_of_code": 128,
          "complexity": 5,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Phase 2 Validation Summary: Before vs After Enhancement\n======================================================\n\nQuick validation showing the transformation from contaminated to authentic features....",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "phase4d_profile_run",
          "file": "scripts/analysis/phase4d_profile_run.py",
          "primary_classes": [
            "PerformanceProfiler"
          ],
          "primary_functions": [
            "run_phase4d_performance_validation",
            "save_profile_csv"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 541,
          "complexity": 45,
          "class_count": 1,
          "function_count": 9,
          "docstring": "Phase 4d: Performance Validation (Full Capability, No Caps)\n==========================================================\nDemonstrate stable end-to-end runs at full sophistication without chunking/caps.\n...",
          "imports": 14,
          "decorators": []
        },
        {
          "name": "run_direct_discovery",
          "file": "scripts/analysis/run_direct_discovery.py",
          "primary_classes": [],
          "primary_functions": [
            "run_direct_discovery"
          ],
          "patterns": [],
          "lines_of_code": 71,
          "complexity": 7,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Direct discovery runner - bypasses TGAT import issues...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "run_manual_discovery",
          "file": "scripts/analysis/run_manual_discovery.py",
          "primary_classes": [],
          "primary_functions": [
            "run_full_discovery"
          ],
          "patterns": [],
          "lines_of_code": 52,
          "complexity": 1,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Manual IRONFORGE runner with Unicode fix...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "daily_htf_workflow",
          "file": "scripts/daily_htf_workflow.py",
          "primary_classes": [
            "DailyHTFWorkflow"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 200,
          "complexity": 19,
          "class_count": 1,
          "function_count": 10,
          "docstring": "Daily HTF Workflow\n================\n\nProduction workflow for HTF-enhanced archaeological discovery.\nRuns the complete pipeline: prep-shards ‚Üí discover ‚Üí score ‚Üí validate ‚Üí report...",
          "imports": 9,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "scripts/data_processing/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 8,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Data Processing Scripts\n================================\nScripts for data transformation, enhancement, and processing pipelines....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "enhanced_session_relativity_processor",
          "file": "scripts/data_processing/enhanced_session_relativity_processor.py",
          "primary_classes": [
            "EnhancedSessionRelativityProcessor"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 491,
          "complexity": 51,
          "class_count": 1,
          "function_count": 7,
          "docstring": "IRONFORGE Enhanced Session Relativity Processor\n===============================================\n\nTransforms absolute price patterns in enhanced sessions into permanent structural relationships.\n\nCriti...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "enhanced_sessions_price_relativity_processor",
          "file": "scripts/data_processing/enhanced_sessions_price_relativity_processor.py",
          "primary_classes": [
            "EnhancedSessionsRelativityProcessor"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 349,
          "complexity": 47,
          "class_count": 1,
          "function_count": 8,
          "docstring": "Enhanced Sessions Price Relativity Processor\n==========================================\n\nApplies price relativity features to the 57 enhanced sessions from Phase 2\nto enable permanent structural patte...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "price_field_standardizer",
          "file": "scripts/data_processing/price_field_standardizer.py",
          "primary_classes": [
            "PriceFieldStandardizer"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 198,
          "complexity": 23,
          "class_count": 1,
          "function_count": 5,
          "docstring": "Price Field Standardizer\n========================\nStandardizes price movement field names across all enhanced sessions.\nConverts 'price' fields to 'price_level' for graph builder compatibility.\n\nFinal...",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "price_relativity_generator",
          "file": "scripts/data_processing/price_relativity_generator.py",
          "primary_classes": [
            "PriceRelativityGenerator"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 582,
          "complexity": 88,
          "class_count": 1,
          "function_count": 8,
          "docstring": "IRONFORGE Price Relativity Feature Generator\n============================================\n\nTransforms absolute price patterns into permanent structural relationships.\n\nCritical Problem Solved:\n- Curre...",
          "imports": 8,
          "decorators": []
        },
        {
          "name": "session_quality_assessor",
          "file": "scripts/data_processing/session_quality_assessor.py",
          "primary_classes": [
            "SessionQualityAssessor"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 439,
          "complexity": 77,
          "class_count": 1,
          "function_count": 9,
          "docstring": "Level 1 Session Quality Assessment Tool\n=====================================\n\nSystematically analyzes Level 1 session data quality to identify artificial patterns\ncausing 96.8% duplication in TGAT mo...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "unicode_fix",
          "file": "scripts/data_processing/unicode_fix.py",
          "primary_classes": [],
          "primary_functions": [
            "sanitize_session_data",
            "load_clean_sessions"
          ],
          "patterns": [],
          "lines_of_code": 43,
          "complexity": 7,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Quick fix for Unicode issues in session data...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "gen_context",
          "file": "scripts/gen_context.py",
          "primary_classes": [],
          "primary_functions": [
            "load_cfg_defaults",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 114,
          "complexity": 21,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Generate a small machine-readable fact sheet for agents.\n\nWrites: docs/context.json\n- Reads configs/dev.yml if available (PyYAML optional).\n- Falls back to NQ/M5 defaults if config not present....",
          "imports": 5,
          "decorators": []
        },
        {
          "name": "process_full_corpus_htf",
          "file": "scripts/process_full_corpus_htf.py",
          "primary_classes": [],
          "primary_functions": [
            "run_prep_shards_htf",
            "validate_htf_features"
          ],
          "patterns": [],
          "lines_of_code": 236,
          "complexity": 21,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Process Full Corpus with HTF Context\n===================================\n\nSafely processes the full IRONFORGE session archive with HTF context enabled,\nmaintaining both baseline and HTF-enhanced shard...",
          "imports": 6,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "scripts/utilities/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 8,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "IRONFORGE Utility Scripts\n=========================\nGeneral utility scripts for debugging, monitoring, and system utilities....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "benchmark_performance",
          "file": "scripts/utilities/benchmark_performance.py",
          "primary_classes": [],
          "primary_functions": [
            "measure_import_time",
            "benchmark_core_imports",
            "benchmark_container_loading",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 163,
          "complexity": 19,
          "class_count": 0,
          "function_count": 4,
          "docstring": "IRONFORGE Performance Benchmark\n==============================\nMeasures import times and system performance to validate refactoring claims....",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "daily_discovery_workflows",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "primary_classes": [
            "MarketAnalysis",
            "SessionDiscoveryResult",
            "DailyDiscoveryWorkflows"
          ],
          "primary_functions": [
            "morning_prep",
            "hunt_patterns",
            "full_market_intel"
          ],
          "patterns": [],
          "lines_of_code": 642,
          "complexity": 91,
          "class_count": 3,
          "function_count": 17,
          "docstring": "IRONFORGE Daily Discovery Workflows\n===================================\nPractical daily-use workflows for pattern discovery and market analysis.\nDesigned for systematic pattern hunting with actionable...",
          "imports": 12,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "debug_features",
          "file": "scripts/utilities/debug_features.py",
          "primary_classes": [],
          "primary_functions": [
            "debug_feature_dimensions"
          ],
          "patterns": [],
          "lines_of_code": 90,
          "complexity": 13,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Debug Price Relativity Feature Dimensions...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "debug_graph_structure",
          "file": "scripts/utilities/debug_graph_structure.py",
          "primary_classes": [],
          "primary_functions": [
            "debug_graph_structure"
          ],
          "patterns": [],
          "lines_of_code": 108,
          "complexity": 18,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Debug Graph Structure\n====================\nDebug the actual graph structure returned by enhanced graph builder....",
          "imports": 4,
          "decorators": []
        },
        {
          "name": "debug_lattice",
          "file": "scripts/utilities/debug_lattice.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 35,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "",
          "imports": 6,
          "decorators": []
        },
        {
          "name": "debug_tgat_init",
          "file": "scripts/utilities/debug_tgat_init.py",
          "primary_classes": [],
          "primary_functions": [
            "debug_tgat_initialization"
          ],
          "patterns": [],
          "lines_of_code": 43,
          "complexity": 2,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Debug TGAT Initialization for Price Relativity...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "example_htf_output",
          "file": "scripts/utilities/example_htf_output.py",
          "primary_classes": [],
          "primary_functions": [
            "demonstrate_htf_integration"
          ],
          "patterns": [],
          "lines_of_code": 159,
          "complexity": 25,
          "class_count": 0,
          "function_count": 1,
          "docstring": "HTF Integration Example - Shows complete multi-timeframe graph output\nDemonstrates the final integrated system with pythonnodes and scale edges...",
          "imports": 2,
          "decorators": []
        },
        {
          "name": "graph_builder_diagnostic",
          "file": "scripts/utilities/graph_builder_diagnostic.py",
          "primary_classes": [],
          "primary_functions": [
            "diagnose_graph_building"
          ],
          "patterns": [],
          "lines_of_code": 120,
          "complexity": 11,
          "class_count": 0,
          "function_count": 1,
          "docstring": "Graph Builder Diagnostic\n========================\nDebug the graph building process to understand 'node_features' error....",
          "imports": 6,
          "decorators": []
        },
        {
          "name": "htf_builder",
          "file": "scripts/utilities/htf_builder.py",
          "primary_classes": [
            "HTFBuilder"
          ],
          "primary_functions": [],
          "patterns": [
            "Factory",
            "Builder"
          ],
          "lines_of_code": 244,
          "complexity": 48,
          "class_count": 1,
          "function_count": 12,
          "docstring": "HTF Builder Improved - Build sophisticated multi-timeframe data for IRONFORGE\nGenerates pythonnodes arrays and htf_cross_map for graph builder integration...",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "ironforge_discovery_sdk",
          "file": "scripts/utilities/ironforge_discovery_sdk.py",
          "primary_classes": [
            "PatternAnalysis",
            "CrossSessionLink",
            "IRONFORGEDiscoverySDK"
          ],
          "primary_functions": [
            "quick_discover_all_sessions",
            "analyze_session_patterns"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 519,
          "complexity": 40,
          "class_count": 3,
          "function_count": 16,
          "docstring": "IRONFORGE Discovery SDK\n======================\nProduction-ready SDK for systematic pattern discovery across 57 enhanced sessions.\nBridges validated archaeological capability into practical daily-use w...",
          "imports": 15,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "pattern_correlation_visualizer",
          "file": "scripts/utilities/pattern_correlation_visualizer.py",
          "primary_classes": [
            "PatternCorrelationVisualizer"
          ],
          "primary_functions": [],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 426,
          "complexity": 33,
          "class_count": 1,
          "function_count": 8,
          "docstring": "IRONFORGE Pattern Correlation Visualizer\n========================================\n\nAdvanced visualization system for pattern correlation analysis.\nReplaces generic statistical charts with actionable t...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "pattern_intelligence",
          "file": "scripts/utilities/pattern_intelligence.py",
          "primary_classes": [
            "PatternTrend",
            "MarketRegime",
            "PatternAlert",
            "PatternIntelligenceEngine"
          ],
          "primary_functions": [
            "analyze_market_intelligence",
            "find_similar_patterns"
          ],
          "patterns": [],
          "lines_of_code": 534,
          "complexity": 43,
          "class_count": 4,
          "function_count": 11,
          "docstring": "IRONFORGE Pattern Intelligence Layer\n===================================\nAdvanced pattern classification, trending analysis, and relationship mapping.\nProvides actionable intelligence from discovered ...",
          "imports": 17,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "pattern_monitor",
          "file": "scripts/utilities/pattern_monitor.py",
          "primary_classes": [
            "PatternMonitor"
          ],
          "primary_functions": [
            "main"
          ],
          "patterns": [],
          "lines_of_code": 251,
          "complexity": 23,
          "class_count": 1,
          "function_count": 9,
          "docstring": "IRONFORGE Pattern Monitor\n=========================\n\nReal-time pattern monitoring and alerting system.\nMonitors for specific patterns and generates alerts.\n\nUsage:\n    python3 pattern_monitor.py [--wa...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "performance_monitor",
          "file": "scripts/utilities/performance_monitor.py",
          "primary_classes": [
            "PerformanceMetrics",
            "PerformanceMonitor"
          ],
          "primary_functions": [
            "monitor_ironforge_session",
            "main",
            "create_graph_analysis",
            "synthetic_processing"
          ],
          "patterns": [
            "Factory"
          ],
          "lines_of_code": 483,
          "complexity": 44,
          "class_count": 2,
          "function_count": 14,
          "docstring": "IRONFORGE Performance Monitor - Sprint 2 Enhancement\n===================================================\n\nMonitors 37D + 4 edge types performance vs baseline to ensure Sprint 2 \nstructural intelligenc...",
          "imports": 12,
          "decorators": [
            "dataclass"
          ]
        },
        {
          "name": "validate-ci",
          "file": "scripts/validate-ci.py",
          "primary_classes": [],
          "primary_functions": [
            "run_command",
            "check_tool_availability",
            "main"
          ],
          "patterns": [],
          "lines_of_code": 111,
          "complexity": 15,
          "class_count": 0,
          "function_count": 3,
          "docstring": "Pre-commit validation script to ensure CI will pass.\nRun this before pushing changes to avoid CI failures.\n\nUsage:\n    python scripts/validate-ci.py...",
          "imports": 4,
          "decorators": []
        }
      ],
      "file_count": 40,
      "total_lines": 10376,
      "complexity_score": 1187,
      "key_classes": [
        {
          "name": "BatchGraphMigrator",
          "file": "data_migration/batch_migrate_graphs.py",
          "docstring": "Batch migration system for IRONFORGE graph files\n\nTechnical Debt Surgeon: Comprehensive batch proces..."
        },
        {
          "name": "SchemaNormalizer",
          "file": "data_migration/schema_normalizer.py",
          "docstring": "Technical Debt Surgeon implementation for schema normalization\nMigrates 34D legacy data to 37D tempo..."
        },
        {
          "name": "PerformanceMonitor",
          "file": "ironforge/utilities/performance_monitor.py",
          "docstring": "Monitor performance of IRONFORGE components\nTrack timing, memory usage, and component initialization..."
        },
        {
          "name": "FeatureAuthenticityValidator",
          "file": "scripts/analysis/phase2_validation_framework.py",
          "docstring": "Validates feature authenticity and provides comprehensive contamination analysis\nbefore and after Ph..."
        },
        {
          "name": "PerformanceProfiler",
          "file": "scripts/analysis/phase4d_profile_run.py",
          "docstring": "Performance profiling harness for IRONFORGE workloads...."
        },
        {
          "name": "DailyHTFWorkflow",
          "file": "scripts/daily_htf_workflow.py",
          "docstring": "Daily production workflow for HTF archaeological discovery..."
        },
        {
          "name": "EnhancedSessionRelativityProcessor",
          "file": "scripts/data_processing/enhanced_session_relativity_processor.py",
          "docstring": "Processes enhanced sessions to add price relativity features\nfor permanent structural pattern discov..."
        },
        {
          "name": "EnhancedSessionsRelativityProcessor",
          "file": "scripts/data_processing/enhanced_sessions_price_relativity_processor.py",
          "docstring": "Processes enhanced sessions to add price relativity features..."
        },
        {
          "name": "PriceFieldStandardizer",
          "file": "scripts/data_processing/price_field_standardizer.py",
          "docstring": "Standardizes price movement field formats for TGAT validation...."
        },
        {
          "name": "PriceRelativityGenerator",
          "file": "scripts/data_processing/price_relativity_generator.py",
          "docstring": "Generates normalized and relational features for permanent pattern discovery..."
        },
        {
          "name": "SessionQualityAssessor",
          "file": "scripts/data_processing/session_quality_assessor.py",
          "docstring": ""
        },
        {
          "name": "MarketAnalysis",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "docstring": "Daily market analysis result..."
        },
        {
          "name": "SessionDiscoveryResult",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "docstring": "Real-time session discovery result..."
        },
        {
          "name": "DailyDiscoveryWorkflows",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "docstring": "Production workflows for daily pattern discovery and market analysis\n\nProvides systematic, actionabl..."
        },
        {
          "name": "HTFBuilder",
          "file": "scripts/utilities/htf_builder.py",
          "docstring": ""
        },
        {
          "name": "PatternAnalysis",
          "file": "scripts/utilities/ironforge_discovery_sdk.py",
          "docstring": "Structured pattern analysis result..."
        },
        {
          "name": "CrossSessionLink",
          "file": "scripts/utilities/ironforge_discovery_sdk.py",
          "docstring": "Cross-session pattern relationship..."
        },
        {
          "name": "IRONFORGEDiscoverySDK",
          "file": "scripts/utilities/ironforge_discovery_sdk.py",
          "docstring": "Production SDK for IRONFORGE archaeological pattern discovery\n\nProvides systematic workflows for dis..."
        },
        {
          "name": "PatternCorrelationVisualizer",
          "file": "scripts/utilities/pattern_correlation_visualizer.py",
          "docstring": "Advanced pattern correlation visualization system..."
        },
        {
          "name": "PatternTrend",
          "file": "scripts/utilities/pattern_intelligence.py",
          "docstring": "Temporal trend in pattern occurrence..."
        },
        {
          "name": "MarketRegime",
          "file": "scripts/utilities/pattern_intelligence.py",
          "docstring": "Identified market regime based on pattern clustering..."
        },
        {
          "name": "PatternAlert",
          "file": "scripts/utilities/pattern_intelligence.py",
          "docstring": "Real-time pattern alert..."
        },
        {
          "name": "PatternIntelligenceEngine",
          "file": "scripts/utilities/pattern_intelligence.py",
          "docstring": "Advanced pattern intelligence system for actionable trading insights\n\nProvides sophisticated analysi..."
        },
        {
          "name": "PatternMonitor",
          "file": "scripts/utilities/pattern_monitor.py",
          "docstring": "Real-time pattern monitoring system..."
        },
        {
          "name": "PerformanceMetrics",
          "file": "scripts/utilities/performance_monitor.py",
          "docstring": "Container for performance measurement results..."
        },
        {
          "name": "PerformanceMonitor",
          "file": "scripts/utilities/performance_monitor.py",
          "docstring": "Monitor IRONFORGE performance with Sprint 2 enhancements\nTracks 37D + 4 edge types vs baseline perfo..."
        }
      ],
      "public_interfaces": [
        {
          "name": "main",
          "file": "data_migration/batch_migrate_graphs.py",
          "parameters": 0,
          "docstring": "Main execution with command line argument parsing..."
        },
        {
          "name": "main",
          "file": "data_migration/schema_normalizer.py",
          "parameters": 0,
          "docstring": "Command-line interface for schema migration..."
        },
        {
          "name": "generate_authentic_htf_carryover",
          "file": "scripts/analysis/complete_phase2_enhancement.py",
          "parameters": 2,
          "docstring": "Generate authentic HTF carryover strength based on market conditions...."
        },
        {
          "name": "generate_authentic_energy_density",
          "file": "scripts/analysis/complete_phase2_enhancement.py",
          "parameters": 2,
          "docstring": "Calculate authentic energy density based on actual market activity...."
        },
        {
          "name": "generate_liquidity_events",
          "file": "scripts/analysis/complete_phase2_enhancement.py",
          "parameters": 2,
          "docstring": "Generate realistic liquidity events based on session characteristics...."
        },
        {
          "name": "enhance_session_features",
          "file": "scripts/analysis/complete_phase2_enhancement.py",
          "parameters": 1,
          "docstring": "Enhance a single session with authentic feature calculations...."
        },
        {
          "name": "process_remaining_sessions",
          "file": "scripts/analysis/complete_phase2_enhancement.py",
          "parameters": 0,
          "docstring": "Process all remaining TGAT-ready sessions for complete Phase 2 coverage...."
        },
        {
          "name": "extract_event_sequences",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 0,
          "docstring": "Extract chronological event sequences from each session..."
        },
        {
          "name": "build_transition_matrices",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 1,
          "docstring": "Build event transition matrices within each session..."
        },
        {
          "name": "analyze_lag_profiles",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 2,
          "docstring": "Calculate lag histograms and consistency metrics for each transition pair..."
        },
        {
          "name": "identify_causal_chains",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 2,
          "docstring": "Identify causal chains with lag consistency >80%..."
        },
        {
          "name": "test_specific_hypothesis",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 2,
          "docstring": "Test specific hypothesis: expansion_phase ‚Üí consolidation ‚Üí liq_sweep..."
        },
        {
          "name": "create_causal_chain_visualization",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 3,
          "docstring": "Create visualization of causal chain discoveries..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/investigate_causal_event_chains.py",
          "parameters": 0,
          "docstring": "Main causal chain investigation..."
        },
        {
          "name": "extract_liquidity_sweep_sequences",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 0,
          "docstring": "Extract all sequences that START with liq_sweep events..."
        },
        {
          "name": "analyze_immediate_responses",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 2,
          "docstring": "Analyze what happens immediately after liq_sweep events..."
        },
        {
          "name": "discover_catalyst_chains",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 2,
          "docstring": "Discover the most common event chains triggered by liq_sweep..."
        },
        {
          "name": "analyze_catalyst_timing_patterns",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 1,
          "docstring": "Analyze when liq_sweeps occur and their effectiveness as catalysts..."
        },
        {
          "name": "test_specific_catalyst_hypotheses",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 1,
          "docstring": "Test specific hypotheses about liq_sweep catalyst behavior..."
        },
        {
          "name": "create_catalyst_visualization",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 4,
          "docstring": "Create comprehensive visualization of liq_sweep catalyst behavior..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/investigate_liquidity_sweep_catalyst.py",
          "parameters": 0,
          "docstring": "Main liquidity sweep catalyst investigation..."
        },
        {
          "name": "main",
          "file": "scripts/analysis/phase2_validation_framework.py",
          "parameters": 0,
          "docstring": "Main validation execution...."
        },
        {
          "name": "validate_decontamination",
          "file": "scripts/analysis/phase2_validation_summary.py",
          "parameters": 0,
          "docstring": "Show before/after decontamination results...."
        },
        {
          "name": "run_phase4d_performance_validation",
          "file": "scripts/analysis/phase4d_profile_run.py",
          "parameters": 0,
          "docstring": "Run Phase 4d performance validation...."
        },
        {
          "name": "save_profile_csv",
          "file": "scripts/analysis/phase4d_profile_run.py",
          "parameters": 1,
          "docstring": "Save profiling results to CSV...."
        },
        {
          "name": "run_direct_discovery",
          "file": "scripts/analysis/run_direct_discovery.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "run_full_discovery",
          "file": "scripts/analysis/run_manual_discovery.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "main",
          "file": "scripts/daily_htf_workflow.py",
          "parameters": 0,
          "docstring": "Main entry point for daily workflow..."
        },
        {
          "name": "main",
          "file": "scripts/data_processing/enhanced_session_relativity_processor.py",
          "parameters": 0,
          "docstring": "Main execution: Transform all enhanced sessions to use price relativity..."
        },
        {
          "name": "main",
          "file": "scripts/data_processing/enhanced_sessions_price_relativity_processor.py",
          "parameters": 0,
          "docstring": "Main execution: Transform all enhanced sessions to use price relativity..."
        },
        {
          "name": "main",
          "file": "scripts/data_processing/price_field_standardizer.py",
          "parameters": 0,
          "docstring": "Run price field standardization...."
        },
        {
          "name": "main",
          "file": "scripts/data_processing/price_relativity_generator.py",
          "parameters": 0,
          "docstring": "Main execution: Transform all HTF sessions to use price relativity\n\nTechnical Debt Surgeon: Enhanced..."
        },
        {
          "name": "main",
          "file": "scripts/data_processing/session_quality_assessor.py",
          "parameters": 0,
          "docstring": "Run complete quality assessment on all Level 1 sessions..."
        },
        {
          "name": "sanitize_session_data",
          "file": "scripts/data_processing/unicode_fix.py",
          "parameters": 1,
          "docstring": "Recursively sanitize all strings in data structure..."
        },
        {
          "name": "load_clean_sessions",
          "file": "scripts/data_processing/unicode_fix.py",
          "parameters": 0,
          "docstring": "Load all sessions with sanitization..."
        },
        {
          "name": "load_cfg_defaults",
          "file": "scripts/gen_context.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "main",
          "file": "scripts/gen_context.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "run_prep_shards_htf",
          "file": "scripts/process_full_corpus_htf.py",
          "parameters": 0,
          "docstring": "Process full corpus with HTF context enabled..."
        },
        {
          "name": "validate_htf_features",
          "file": "scripts/process_full_corpus_htf.py",
          "parameters": 0,
          "docstring": "Quick validation of HTF feature integrity..."
        },
        {
          "name": "measure_import_time",
          "file": "scripts/utilities/benchmark_performance.py",
          "parameters": 2,
          "docstring": "Measure time to import a module and optionally get a class..."
        },
        {
          "name": "benchmark_core_imports",
          "file": "scripts/utilities/benchmark_performance.py",
          "parameters": 0,
          "docstring": "Benchmark core IRONFORGE imports..."
        },
        {
          "name": "benchmark_container_loading",
          "file": "scripts/utilities/benchmark_performance.py",
          "parameters": 0,
          "docstring": "Benchmark lazy loading container performance..."
        },
        {
          "name": "main",
          "file": "scripts/utilities/benchmark_performance.py",
          "parameters": 0,
          "docstring": "Run complete performance benchmark..."
        },
        {
          "name": "morning_prep",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "parameters": 1,
          "docstring": "Quick morning market preparation..."
        },
        {
          "name": "hunt_patterns",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "parameters": 1,
          "docstring": "Quick pattern hunting for specific session..."
        },
        {
          "name": "full_market_intel",
          "file": "scripts/utilities/daily_discovery_workflows.py",
          "parameters": 0,
          "docstring": "Complete daily market intelligence workflow..."
        },
        {
          "name": "debug_feature_dimensions",
          "file": "scripts/utilities/debug_features.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "debug_graph_structure",
          "file": "scripts/utilities/debug_graph_structure.py",
          "parameters": 0,
          "docstring": "Debug the actual graph structure...."
        },
        {
          "name": "debug_tgat_initialization",
          "file": "scripts/utilities/debug_tgat_init.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "demonstrate_htf_integration",
          "file": "scripts/utilities/example_htf_output.py",
          "parameters": 0,
          "docstring": "Create example HTF output showing all features..."
        },
        {
          "name": "diagnose_graph_building",
          "file": "scripts/utilities/graph_builder_diagnostic.py",
          "parameters": 0,
          "docstring": "Diagnose what's happening in graph building process...."
        },
        {
          "name": "quick_discover_all_sessions",
          "file": "scripts/utilities/ironforge_discovery_sdk.py",
          "parameters": 0,
          "docstring": "Quick function to run discovery on all sessions..."
        },
        {
          "name": "analyze_session_patterns",
          "file": "scripts/utilities/ironforge_discovery_sdk.py",
          "parameters": 1,
          "docstring": "Quick function to analyze patterns in a specific session..."
        },
        {
          "name": "analyze_market_intelligence",
          "file": "scripts/utilities/pattern_intelligence.py",
          "parameters": 0,
          "docstring": "Complete market intelligence analysis workflow..."
        },
        {
          "name": "find_similar_patterns",
          "file": "scripts/utilities/pattern_intelligence.py",
          "parameters": 2,
          "docstring": "Find patterns similar to a specific pattern from a session..."
        },
        {
          "name": "main",
          "file": "scripts/utilities/pattern_monitor.py",
          "parameters": 0,
          "docstring": ""
        },
        {
          "name": "monitor_ironforge_session",
          "file": "scripts/utilities/performance_monitor.py",
          "parameters": 3,
          "docstring": "Convenience function to monitor a complete IRONFORGE session\n\nArgs:\n    session_data: Input session ..."
        },
        {
          "name": "main",
          "file": "scripts/utilities/performance_monitor.py",
          "parameters": 0,
          "docstring": "Command-line interface for performance monitoring..."
        },
        {
          "name": "create_graph_analysis",
          "file": "scripts/utilities/performance_monitor.py",
          "parameters": 2,
          "docstring": "Create graph analysis for performance monitoring..."
        },
        {
          "name": "synthetic_processing",
          "file": "scripts/utilities/performance_monitor.py",
          "parameters": 1,
          "docstring": "Synthetic processing function for testing..."
        },
        {
          "name": "run_command",
          "file": "scripts/validate-ci.py",
          "parameters": 2,
          "docstring": "Run a command and return success/failure...."
        },
        {
          "name": "check_tool_availability",
          "file": "scripts/validate-ci.py",
          "parameters": 0,
          "docstring": "Check if all required tools are available...."
        },
        {
          "name": "main",
          "file": "scripts/validate-ci.py",
          "parameters": 0,
          "docstring": "Main validation workflow...."
        }
      ],
      "avg_complexity": 29.68
    },
    "data": {
      "description": "Data storage and preservation",
      "components": [
        {
          "name": "__init__",
          "file": "ironforge/converters/__init__.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 1,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Converters for transforming data between formats in IRONFORGE pipeline....",
          "imports": 0,
          "decorators": []
        },
        {
          "name": "__init__",
          "file": "ironforge/data_engine/__init__.py",
          "primary_classes": [],
          "primary_functions": [
            "write_nodes",
            "write_edges"
          ],
          "patterns": [],
          "lines_of_code": 37,
          "complexity": 2,
          "class_count": 0,
          "function_count": 2,
          "docstring": "Data engine utilities for IRONFORGE.\n\nThis module re-exports the authoritative data engine implementation\nlocated in the legacy `IRONFORGE` package so that consumers can import\n`ironforge.data_engine`...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "parquet_reader",
          "file": "ironforge/data_engine/parquet_reader.py",
          "primary_classes": [],
          "primary_functions": [
            "read_nodes_edges"
          ],
          "patterns": [],
          "lines_of_code": 14,
          "complexity": 1,
          "class_count": 0,
          "function_count": 1,
          "docstring": "",
          "imports": 3,
          "decorators": []
        },
        {
          "name": "parquet_writer",
          "file": "ironforge/data_engine/parquet_writer.py",
          "primary_classes": [],
          "primary_functions": [
            "write_nodes",
            "write_edges"
          ],
          "patterns": [],
          "lines_of_code": 58,
          "complexity": 10,
          "class_count": 0,
          "function_count": 5,
          "docstring": "Validated Parquet writers for nodes and edges.\n\nThis implementation mirrors the original utilities but guards the\noptional ``pyarrow`` dependency so that importing the module does not\nraise when ``pya...",
          "imports": 7,
          "decorators": []
        },
        {
          "name": "schemas",
          "file": "ironforge/data_engine/schemas.py",
          "primary_classes": [],
          "primary_functions": [],
          "patterns": [],
          "lines_of_code": 16,
          "complexity": 0,
          "class_count": 0,
          "function_count": 0,
          "docstring": "Authoritative column definitions and data types for IRONFORGE data storage....",
          "imports": 0,
          "decorators": []
        }
      ],
      "file_count": 5,
      "total_lines": 126,
      "complexity_score": 13,
      "key_classes": [],
      "public_interfaces": [
        {
          "name": "write_nodes",
          "file": "ironforge/data_engine/__init__.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "write_edges",
          "file": "ironforge/data_engine/__init__.py",
          "parameters": 2,
          "docstring": ""
        },
        {
          "name": "read_nodes_edges",
          "file": "ironforge/data_engine/parquet_reader.py",
          "parameters": 1,
          "docstring": "Read node and edge Parquet files for a shard directory...."
        },
        {
          "name": "write_nodes",
          "file": "ironforge/data_engine/parquet_writer.py",
          "parameters": 2,
          "docstring": "Write nodes DataFrame to Parquet with validation...."
        },
        {
          "name": "write_edges",
          "file": "ironforge/data_engine/parquet_writer.py",
          "parameters": 2,
          "docstring": "Write edges DataFrame to Parquet with validation...."
        }
      ],
      "avg_complexity": 2.6
    },
    "metadata": {
      "total_files_classified": 149,
      "unclassified_files": [
        "ironforge/__version__.py",
        "ironforge/confluence/__init__.py",
        "ironforge/motifs/__init__.py",
        "ironforge/motifs/scanner.py",
        "ironforge/sdk/__init__.py",
        "ironforge/sdk/io.py"
      ],
      "classification_coverage": 96.13,
      "engine_distribution": {
        "analysis": 51,
        "learning": 12,
        "synthesis": 3,
        "integration": 28,
        "validation": 7,
        "reporting": 3,
        "utilities": 40,
        "data": 5
      }
    }
  },
  "summary": {
    "total_engines": 8,
    "total_components": 149,
    "engine_distribution": {
      "analysis": 51,
      "learning": 12,
      "synthesis": 3,
      "integration": 28,
      "validation": 7,
      "reporting": 3,
      "utilities": 40,
      "data": 5
    }
  }
}