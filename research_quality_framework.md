# IRONFORGE Research Quality Framework
## Preventing Agent Enthusiasm Bias

### DISCOVERY CLASSIFICATION LEVELS

#### Level 1: OBSERVATION
- Pattern noted in data
- Correlation identified
- No causal claims
- Language: "observed", "noted", "identified"

#### Level 2: CORRELATION
- Statistical relationship established
- P-values < 0.05 with adequate sample size
- Alternative explanations considered
- Language: "correlates", "associated with", "related to"

#### Level 3: VALIDATED PATTERN  
- Replicated across multiple datasets
- Cross-validated with independent data
- Statistical significance confirmed
- Language: "validated", "confirmed", "established"

#### Level 4: PREDICTIVE MODEL
- Forward-looking accuracy demonstrated
- Out-of-sample testing completed
- Performance metrics documented
- Language: "predicts", "forecasts", "anticipates"

#### Level 5: BREAKTHROUGH
- Fundamental change in understanding
- Multiple independent validations
- Peer review or equivalent scrutiny
- Language: "breakthrough", "revolutionary", "paradigm shift"

### BANNED LANGUAGE WITHOUT VALIDATION

âŒ "Breakthrough" without Level 5 validation
âŒ "Revolutionary" without paradigm evidence  
âŒ "Proven" without statistical significance
âŒ "Perfect" without comprehensive testing
âŒ "Production ready" without deployment testing

### AGENT INSTRUCTION TEMPLATE

```
You are a [ROLE] agent. Your findings must be classified using the Research Quality Framework:

- Use conservative language appropriate to evidence level
- Acknowledge limitations and uncertainties
- Provide alternative explanations
- Include sample sizes and statistical measures
- Distinguish between correlation and causation
- Request additional validation when needed

Report format:
1. DISCOVERY LEVEL: [1-5]
2. EVIDENCE BASIS: [sample size, statistical measures]
3. LIMITATIONS: [what cannot be concluded]
4. ALTERNATIVE EXPLANATIONS: [simpler possibilities]
5. NEXT STEPS: [what validation is needed]
```

### VALIDATION CHECKLIST

Before accepting any "breakthrough" claim:

â˜ Sample size adequate (n > 30 minimum)
â˜ Statistical significance reported (p-values)
â˜ Effect size meaningful (not just significant)
â˜ Alternative explanations considered
â˜ Reproducibility demonstrated
â˜ Language matches evidence level
â˜ Limitations clearly stated
â˜ Independent validation completed

### COMMON AGENT ENTHUSIASM PATTERNS TO WATCH

1. **Task Completion Bias**: Claiming success to complete assignment
2. **Confirmation Bias**: Finding patterns that support hypothesis
3. **Language Inflation**: Using dramatic terms for modest findings
4. **Causal Overreach**: Inferring causation from correlation
5. **Sample Size Minimization**: Drawing broad conclusions from limited data
6. **Complexity Bias**: Preferring complex explanations over simple ones

### RED FLAGS FOR INVALID CLAIMS

ðŸš© Percentage improvements >100% without clear baseline
ðŸš© "Perfect" correlations (r=1.00) in noisy financial data
ðŸš© Sample sizes n<10 for statistical claims
ðŸš© Missing p-values or confidence intervals
ðŸš© Claims of "production readiness" without testing
ðŸš© Theory names ("gravitational field") for simple correlations
ðŸš© Requests for human implementation of "completed" algorithms

### SOLUTION IMPLEMENTATION

1. **All agents receive Research Quality Framework training**
2. **Validation agent applies skeptical evaluation to all claims**
3. **Orchestrator enforces conservative language requirements**
4. **Regular calibration sessions to prevent drift**
5. **Independent external validation for Level 4+ claims**